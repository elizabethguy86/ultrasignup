{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.ensemble import GradientBoostingClassifier as GBC\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import log_loss, auc, roc_curve, roc_auc_score\n",
    "from sklearn.neighbors import KNeighborsClassifier as knn\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 12, 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#data = pd.read_csv('../ult_sign_scrape/race_master/master_database.csv')\n",
    "fe4 = pd.read_csv('../ult_sign_scrape/race_master/master_database_fe4.csv')\n",
    "athletes = pd.read_csv('../ult_sign_scrape/athlete_dataframe/concat')\n",
    "races = pd.read_csv('../ult_sign_scrape/race_master/master_list.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#clean = data.drop(['Unnamed: 0', 'Unnamed: 0.1'], axis=1)\n",
    "fe4_clean = fe4.drop(['Unnamed: 0', 'Unnamed: 0.1'], axis=1)\n",
    "fe4 = fe4_clean.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>participant_id</th>\n",
       "      <th>runner_rank</th>\n",
       "      <th>status</th>\n",
       "      <th>race_id</th>\n",
       "      <th>Season</th>\n",
       "      <th>Metro_area</th>\n",
       "      <th>WL_SO</th>\n",
       "      <th>Entry_fee</th>\n",
       "      <th>PPM</th>\n",
       "      <th>Age_Rank</th>\n",
       "      <th>Gender_Rank</th>\n",
       "      <th>Total_races</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.270411</td>\n",
       "      <td>-0.216783</td>\n",
       "      <td>0.075115</td>\n",
       "      <td>-0.010206</td>\n",
       "      <td>0.047769</td>\n",
       "      <td>0.018868</td>\n",
       "      <td>-0.043341</td>\n",
       "      <td>0.043721</td>\n",
       "      <td>-0.016771</td>\n",
       "      <td>-0.007417</td>\n",
       "      <td>0.000602</td>\n",
       "      <td>0.011360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>participant_id</th>\n",
       "      <td>-0.270411</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.194335</td>\n",
       "      <td>-0.001664</td>\n",
       "      <td>0.386143</td>\n",
       "      <td>-0.020922</td>\n",
       "      <td>0.029178</td>\n",
       "      <td>-0.089945</td>\n",
       "      <td>-0.122077</td>\n",
       "      <td>-0.070901</td>\n",
       "      <td>-0.005315</td>\n",
       "      <td>-0.005174</td>\n",
       "      <td>-0.015240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>runner_rank</th>\n",
       "      <td>-0.216783</td>\n",
       "      <td>-0.194335</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.190380</td>\n",
       "      <td>0.020117</td>\n",
       "      <td>-0.074137</td>\n",
       "      <td>-0.018915</td>\n",
       "      <td>0.115371</td>\n",
       "      <td>-0.045335</td>\n",
       "      <td>0.113499</td>\n",
       "      <td>-0.003333</td>\n",
       "      <td>-0.008166</td>\n",
       "      <td>0.007546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>status</th>\n",
       "      <td>0.075115</td>\n",
       "      <td>-0.001664</td>\n",
       "      <td>-0.190380</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.032448</td>\n",
       "      <td>0.079697</td>\n",
       "      <td>-0.038195</td>\n",
       "      <td>-0.150429</td>\n",
       "      <td>-0.094013</td>\n",
       "      <td>-0.118026</td>\n",
       "      <td>0.007557</td>\n",
       "      <td>0.009809</td>\n",
       "      <td>-0.000989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race_id</th>\n",
       "      <td>-0.010206</td>\n",
       "      <td>0.386143</td>\n",
       "      <td>0.020117</td>\n",
       "      <td>0.032448</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.058049</td>\n",
       "      <td>0.130348</td>\n",
       "      <td>-0.123373</td>\n",
       "      <td>-0.212501</td>\n",
       "      <td>0.017266</td>\n",
       "      <td>-0.015521</td>\n",
       "      <td>-0.024019</td>\n",
       "      <td>-0.029799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Season</th>\n",
       "      <td>0.047769</td>\n",
       "      <td>-0.020922</td>\n",
       "      <td>-0.074137</td>\n",
       "      <td>0.079697</td>\n",
       "      <td>-0.058049</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.229057</td>\n",
       "      <td>-0.543905</td>\n",
       "      <td>-0.242692</td>\n",
       "      <td>-0.293994</td>\n",
       "      <td>-0.004094</td>\n",
       "      <td>-0.006021</td>\n",
       "      <td>0.019240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Metro_area</th>\n",
       "      <td>0.018868</td>\n",
       "      <td>0.029178</td>\n",
       "      <td>-0.018915</td>\n",
       "      <td>-0.038195</td>\n",
       "      <td>0.130348</td>\n",
       "      <td>-0.229057</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.292363</td>\n",
       "      <td>0.117692</td>\n",
       "      <td>0.406314</td>\n",
       "      <td>-0.010899</td>\n",
       "      <td>-0.017804</td>\n",
       "      <td>-0.007776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WL_SO</th>\n",
       "      <td>-0.043341</td>\n",
       "      <td>-0.089945</td>\n",
       "      <td>0.115371</td>\n",
       "      <td>-0.150429</td>\n",
       "      <td>-0.123373</td>\n",
       "      <td>-0.543905</td>\n",
       "      <td>-0.292363</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.413294</td>\n",
       "      <td>0.319025</td>\n",
       "      <td>0.028082</td>\n",
       "      <td>0.026839</td>\n",
       "      <td>0.006227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Entry_fee</th>\n",
       "      <td>0.043721</td>\n",
       "      <td>-0.122077</td>\n",
       "      <td>-0.045335</td>\n",
       "      <td>-0.094013</td>\n",
       "      <td>-0.212501</td>\n",
       "      <td>-0.242692</td>\n",
       "      <td>0.117692</td>\n",
       "      <td>0.413294</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.334784</td>\n",
       "      <td>0.001548</td>\n",
       "      <td>-0.006640</td>\n",
       "      <td>-0.006176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PPM</th>\n",
       "      <td>-0.016771</td>\n",
       "      <td>-0.070901</td>\n",
       "      <td>0.113499</td>\n",
       "      <td>-0.118026</td>\n",
       "      <td>0.017266</td>\n",
       "      <td>-0.293994</td>\n",
       "      <td>0.406314</td>\n",
       "      <td>0.319025</td>\n",
       "      <td>0.334784</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003491</td>\n",
       "      <td>-0.017046</td>\n",
       "      <td>0.017571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age_Rank</th>\n",
       "      <td>-0.007417</td>\n",
       "      <td>-0.005315</td>\n",
       "      <td>-0.003333</td>\n",
       "      <td>0.007557</td>\n",
       "      <td>-0.015521</td>\n",
       "      <td>-0.004094</td>\n",
       "      <td>-0.010899</td>\n",
       "      <td>0.028082</td>\n",
       "      <td>0.001548</td>\n",
       "      <td>0.003491</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.766592</td>\n",
       "      <td>0.177129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gender_Rank</th>\n",
       "      <td>0.000602</td>\n",
       "      <td>-0.005174</td>\n",
       "      <td>-0.008166</td>\n",
       "      <td>0.009809</td>\n",
       "      <td>-0.024019</td>\n",
       "      <td>-0.006021</td>\n",
       "      <td>-0.017804</td>\n",
       "      <td>0.026839</td>\n",
       "      <td>-0.006640</td>\n",
       "      <td>-0.017046</td>\n",
       "      <td>0.766592</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.157633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total_races</th>\n",
       "      <td>0.011360</td>\n",
       "      <td>-0.015240</td>\n",
       "      <td>0.007546</td>\n",
       "      <td>-0.000989</td>\n",
       "      <td>-0.029799</td>\n",
       "      <td>0.019240</td>\n",
       "      <td>-0.007776</td>\n",
       "      <td>0.006227</td>\n",
       "      <td>-0.006176</td>\n",
       "      <td>0.017571</td>\n",
       "      <td>0.177129</td>\n",
       "      <td>0.157633</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     age  participant_id  runner_rank    status   race_id  \\\n",
       "age             1.000000       -0.270411    -0.216783  0.075115 -0.010206   \n",
       "participant_id -0.270411        1.000000    -0.194335 -0.001664  0.386143   \n",
       "runner_rank    -0.216783       -0.194335     1.000000 -0.190380  0.020117   \n",
       "status          0.075115       -0.001664    -0.190380  1.000000  0.032448   \n",
       "race_id        -0.010206        0.386143     0.020117  0.032448  1.000000   \n",
       "Season          0.047769       -0.020922    -0.074137  0.079697 -0.058049   \n",
       "Metro_area      0.018868        0.029178    -0.018915 -0.038195  0.130348   \n",
       "WL_SO          -0.043341       -0.089945     0.115371 -0.150429 -0.123373   \n",
       "Entry_fee       0.043721       -0.122077    -0.045335 -0.094013 -0.212501   \n",
       "PPM            -0.016771       -0.070901     0.113499 -0.118026  0.017266   \n",
       "Age_Rank       -0.007417       -0.005315    -0.003333  0.007557 -0.015521   \n",
       "Gender_Rank     0.000602       -0.005174    -0.008166  0.009809 -0.024019   \n",
       "Total_races     0.011360       -0.015240     0.007546 -0.000989 -0.029799   \n",
       "\n",
       "                  Season  Metro_area     WL_SO  Entry_fee       PPM  Age_Rank  \\\n",
       "age             0.047769    0.018868 -0.043341   0.043721 -0.016771 -0.007417   \n",
       "participant_id -0.020922    0.029178 -0.089945  -0.122077 -0.070901 -0.005315   \n",
       "runner_rank    -0.074137   -0.018915  0.115371  -0.045335  0.113499 -0.003333   \n",
       "status          0.079697   -0.038195 -0.150429  -0.094013 -0.118026  0.007557   \n",
       "race_id        -0.058049    0.130348 -0.123373  -0.212501  0.017266 -0.015521   \n",
       "Season          1.000000   -0.229057 -0.543905  -0.242692 -0.293994 -0.004094   \n",
       "Metro_area     -0.229057    1.000000 -0.292363   0.117692  0.406314 -0.010899   \n",
       "WL_SO          -0.543905   -0.292363  1.000000   0.413294  0.319025  0.028082   \n",
       "Entry_fee      -0.242692    0.117692  0.413294   1.000000  0.334784  0.001548   \n",
       "PPM            -0.293994    0.406314  0.319025   0.334784  1.000000  0.003491   \n",
       "Age_Rank       -0.004094   -0.010899  0.028082   0.001548  0.003491  1.000000   \n",
       "Gender_Rank    -0.006021   -0.017804  0.026839  -0.006640 -0.017046  0.766592   \n",
       "Total_races     0.019240   -0.007776  0.006227  -0.006176  0.017571  0.177129   \n",
       "\n",
       "                Gender_Rank  Total_races  \n",
       "age                0.000602     0.011360  \n",
       "participant_id    -0.005174    -0.015240  \n",
       "runner_rank       -0.008166     0.007546  \n",
       "status             0.009809    -0.000989  \n",
       "race_id           -0.024019    -0.029799  \n",
       "Season            -0.006021     0.019240  \n",
       "Metro_area        -0.017804    -0.007776  \n",
       "WL_SO              0.026839     0.006227  \n",
       "Entry_fee         -0.006640    -0.006176  \n",
       "PPM               -0.017046     0.017571  \n",
       "Age_Rank           0.766592     0.177129  \n",
       "Gender_Rank        1.000000     0.157633  \n",
       "Total_races        0.157633     1.000000  "
      ]
     },
     "execution_count": 1180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fe4.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting observation - Very little spread between 25-75% in age of entrants (35-49). Max is 79 and min is ~12 (some cleaning of 0/1 ages may be necessary). 39-44 is the most common ages with nearly 400 in each category. Mid-life crisis???\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting observation - Appears that runner rank and age have the strongest relationships to the status column. Gender rank and age rank are similar in their relationship. Total races appears to have the weakest relationship for these features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gender_dummies_fe = pd.get_dummies(fe4.gender, prefix='gender')\n",
    "#state_dummies = pd.get_dummies(fe2_clean.state, prefix='Home_State')\n",
    "fe4 = fe4.join(gender_dummies_fe)\n",
    "#fe4_clean = fe4_clean.join(state_dummies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Coding:\n",
      "1    6291\n",
      "2    3930\n",
      "3     540\n",
      "Name: status, dtype: int64\n",
      "\n",
      "After Coding:\n",
      "1    10221\n",
      "0      540\n",
      "Name: status_coded, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>participant_id</th>\n",
       "      <th>runner_rank</th>\n",
       "      <th>race_id</th>\n",
       "      <th>race_name</th>\n",
       "      <th>Season</th>\n",
       "      <th>Metro_area</th>\n",
       "      <th>WL_SO</th>\n",
       "      <th>Entry_fee</th>\n",
       "      <th>PPM</th>\n",
       "      <th>Age_Rank</th>\n",
       "      <th>Gender_Rank</th>\n",
       "      <th>Total_races</th>\n",
       "      <th>gender_F</th>\n",
       "      <th>gender_M</th>\n",
       "      <th>status_coded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26</td>\n",
       "      <td>M</td>\n",
       "      <td>7148</td>\n",
       "      <td>88.39</td>\n",
       "      <td>11470</td>\n",
       "      <td>Bear</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.7174</td>\n",
       "      <td>0.6806</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33</td>\n",
       "      <td>M</td>\n",
       "      <td>221721</td>\n",
       "      <td>90.00</td>\n",
       "      <td>11470</td>\n",
       "      <td>Bear</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.8132</td>\n",
       "      <td>0.6987</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>43</td>\n",
       "      <td>M</td>\n",
       "      <td>20020</td>\n",
       "      <td>83.63</td>\n",
       "      <td>11470</td>\n",
       "      <td>Bear</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.8272</td>\n",
       "      <td>0.7145</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36</td>\n",
       "      <td>M</td>\n",
       "      <td>25441</td>\n",
       "      <td>73.22</td>\n",
       "      <td>11470</td>\n",
       "      <td>Bear</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.8995</td>\n",
       "      <td>0.8957</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>M</td>\n",
       "      <td>22562</td>\n",
       "      <td>87.77</td>\n",
       "      <td>11470</td>\n",
       "      <td>Bear</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.6807</td>\n",
       "      <td>0.6522</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age gender  participant_id  runner_rank  race_id race_name  Season  \\\n",
       "0   26      M            7148        88.39    11470      Bear       3   \n",
       "1   33      M          221721        90.00    11470      Bear       3   \n",
       "2   43      M           20020        83.63    11470      Bear       3   \n",
       "3   36      M           25441        73.22    11470      Bear       3   \n",
       "4   33      M           22562        87.77    11470      Bear       3   \n",
       "\n",
       "   Metro_area  WL_SO  Entry_fee  PPM  Age_Rank  Gender_Rank  Total_races  \\\n",
       "0           0      1          1  2.5    0.7174       0.6806         23.0   \n",
       "1           0      1          1  2.5    0.8132       0.6987          9.0   \n",
       "2           0      1          1  2.5    0.8272       0.7145         17.0   \n",
       "3           0      1          1  2.5    0.8995       0.8957         18.0   \n",
       "4           0      1          1  2.5    0.6807       0.6522          8.0   \n",
       "\n",
       "   gender_F  gender_M  status_coded  \n",
       "0       0.0       1.0             1  \n",
       "1       0.0       1.0             1  \n",
       "2       0.0       1.0             1  \n",
       "3       0.0       1.0             1  \n",
       "4       0.0       1.0             1  "
      ]
     },
     "execution_count": 1182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def coding(col, codeDict):\n",
    "    colCoded = pd.Series(col, copy=True)\n",
    "    for key, value in codeDict.items():\n",
    "        colCoded.replace(key, value, inplace=True)\n",
    "    return colCoded\n",
    " \n",
    "\n",
    "print 'Before Coding:'\n",
    "print pd.value_counts(fe4[\"status\"])\n",
    "fe4[\"status_coded\"] = coding(fe4[\"status\"], {'1':1,'2':1, '3':0})\n",
    "print '\\nAfter Coding:'\n",
    "print pd.value_counts(fe4[\"status_coded\"])\n",
    "fe4 = fe4.drop(['status'], axis=1)\n",
    "fe4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>participant_id</th>\n",
       "      <th>runner_rank</th>\n",
       "      <th>race_id</th>\n",
       "      <th>Season</th>\n",
       "      <th>Metro_area</th>\n",
       "      <th>WL_SO</th>\n",
       "      <th>Entry_fee</th>\n",
       "      <th>PPM</th>\n",
       "      <th>Age_Rank</th>\n",
       "      <th>Gender_Rank</th>\n",
       "      <th>Total_races</th>\n",
       "      <th>gender_F</th>\n",
       "      <th>gender_M</th>\n",
       "      <th>status_coded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.270411</td>\n",
       "      <td>-0.216783</td>\n",
       "      <td>-0.010206</td>\n",
       "      <td>0.047769</td>\n",
       "      <td>0.018868</td>\n",
       "      <td>-0.043341</td>\n",
       "      <td>0.043721</td>\n",
       "      <td>-0.016771</td>\n",
       "      <td>-0.007417</td>\n",
       "      <td>0.000602</td>\n",
       "      <td>0.011360</td>\n",
       "      <td>-0.050618</td>\n",
       "      <td>0.050618</td>\n",
       "      <td>0.011733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>participant_id</th>\n",
       "      <td>-0.270411</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.194335</td>\n",
       "      <td>0.386143</td>\n",
       "      <td>-0.020922</td>\n",
       "      <td>0.029178</td>\n",
       "      <td>-0.089945</td>\n",
       "      <td>-0.122077</td>\n",
       "      <td>-0.070901</td>\n",
       "      <td>-0.005315</td>\n",
       "      <td>-0.005174</td>\n",
       "      <td>-0.015240</td>\n",
       "      <td>-0.026327</td>\n",
       "      <td>0.026327</td>\n",
       "      <td>-0.019896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>runner_rank</th>\n",
       "      <td>-0.216783</td>\n",
       "      <td>-0.194335</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.020117</td>\n",
       "      <td>-0.074137</td>\n",
       "      <td>-0.018915</td>\n",
       "      <td>0.115371</td>\n",
       "      <td>-0.045335</td>\n",
       "      <td>0.113499</td>\n",
       "      <td>-0.003333</td>\n",
       "      <td>-0.008166</td>\n",
       "      <td>0.007546</td>\n",
       "      <td>0.197594</td>\n",
       "      <td>-0.197594</td>\n",
       "      <td>0.002527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race_id</th>\n",
       "      <td>-0.010206</td>\n",
       "      <td>0.386143</td>\n",
       "      <td>0.020117</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.058049</td>\n",
       "      <td>0.130348</td>\n",
       "      <td>-0.123373</td>\n",
       "      <td>-0.212501</td>\n",
       "      <td>0.017266</td>\n",
       "      <td>-0.015521</td>\n",
       "      <td>-0.024019</td>\n",
       "      <td>-0.029799</td>\n",
       "      <td>-0.021824</td>\n",
       "      <td>0.021824</td>\n",
       "      <td>-0.081115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Season</th>\n",
       "      <td>0.047769</td>\n",
       "      <td>-0.020922</td>\n",
       "      <td>-0.074137</td>\n",
       "      <td>-0.058049</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.229057</td>\n",
       "      <td>-0.543905</td>\n",
       "      <td>-0.242692</td>\n",
       "      <td>-0.293994</td>\n",
       "      <td>-0.004094</td>\n",
       "      <td>-0.006021</td>\n",
       "      <td>0.019240</td>\n",
       "      <td>0.011332</td>\n",
       "      <td>-0.011332</td>\n",
       "      <td>-0.035099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Metro_area</th>\n",
       "      <td>0.018868</td>\n",
       "      <td>0.029178</td>\n",
       "      <td>-0.018915</td>\n",
       "      <td>0.130348</td>\n",
       "      <td>-0.229057</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.292363</td>\n",
       "      <td>0.117692</td>\n",
       "      <td>0.406314</td>\n",
       "      <td>-0.010899</td>\n",
       "      <td>-0.017804</td>\n",
       "      <td>-0.007776</td>\n",
       "      <td>0.072808</td>\n",
       "      <td>-0.072808</td>\n",
       "      <td>0.063267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WL_SO</th>\n",
       "      <td>-0.043341</td>\n",
       "      <td>-0.089945</td>\n",
       "      <td>0.115371</td>\n",
       "      <td>-0.123373</td>\n",
       "      <td>-0.543905</td>\n",
       "      <td>-0.292363</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.413294</td>\n",
       "      <td>0.319025</td>\n",
       "      <td>0.028082</td>\n",
       "      <td>0.026839</td>\n",
       "      <td>0.006227</td>\n",
       "      <td>-0.052848</td>\n",
       "      <td>0.052848</td>\n",
       "      <td>0.053033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Entry_fee</th>\n",
       "      <td>0.043721</td>\n",
       "      <td>-0.122077</td>\n",
       "      <td>-0.045335</td>\n",
       "      <td>-0.212501</td>\n",
       "      <td>-0.242692</td>\n",
       "      <td>0.117692</td>\n",
       "      <td>0.413294</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.334784</td>\n",
       "      <td>0.001548</td>\n",
       "      <td>-0.006640</td>\n",
       "      <td>-0.006176</td>\n",
       "      <td>0.036295</td>\n",
       "      <td>-0.036295</td>\n",
       "      <td>0.150438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PPM</th>\n",
       "      <td>-0.016771</td>\n",
       "      <td>-0.070901</td>\n",
       "      <td>0.113499</td>\n",
       "      <td>0.017266</td>\n",
       "      <td>-0.293994</td>\n",
       "      <td>0.406314</td>\n",
       "      <td>0.319025</td>\n",
       "      <td>0.334784</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003491</td>\n",
       "      <td>-0.017046</td>\n",
       "      <td>0.017571</td>\n",
       "      <td>0.000985</td>\n",
       "      <td>-0.000985</td>\n",
       "      <td>0.066751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age_Rank</th>\n",
       "      <td>-0.007417</td>\n",
       "      <td>-0.005315</td>\n",
       "      <td>-0.003333</td>\n",
       "      <td>-0.015521</td>\n",
       "      <td>-0.004094</td>\n",
       "      <td>-0.010899</td>\n",
       "      <td>0.028082</td>\n",
       "      <td>0.001548</td>\n",
       "      <td>0.003491</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.766592</td>\n",
       "      <td>0.177129</td>\n",
       "      <td>0.000289</td>\n",
       "      <td>-0.000289</td>\n",
       "      <td>0.007534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gender_Rank</th>\n",
       "      <td>0.000602</td>\n",
       "      <td>-0.005174</td>\n",
       "      <td>-0.008166</td>\n",
       "      <td>-0.024019</td>\n",
       "      <td>-0.006021</td>\n",
       "      <td>-0.017804</td>\n",
       "      <td>0.026839</td>\n",
       "      <td>-0.006640</td>\n",
       "      <td>-0.017046</td>\n",
       "      <td>0.766592</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.157633</td>\n",
       "      <td>0.003349</td>\n",
       "      <td>-0.003349</td>\n",
       "      <td>0.002545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total_races</th>\n",
       "      <td>0.011360</td>\n",
       "      <td>-0.015240</td>\n",
       "      <td>0.007546</td>\n",
       "      <td>-0.029799</td>\n",
       "      <td>0.019240</td>\n",
       "      <td>-0.007776</td>\n",
       "      <td>0.006227</td>\n",
       "      <td>-0.006176</td>\n",
       "      <td>0.017571</td>\n",
       "      <td>0.177129</td>\n",
       "      <td>0.157633</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.001369</td>\n",
       "      <td>0.001369</td>\n",
       "      <td>0.008308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender_F</th>\n",
       "      <td>-0.050618</td>\n",
       "      <td>-0.026327</td>\n",
       "      <td>0.197594</td>\n",
       "      <td>-0.021824</td>\n",
       "      <td>0.011332</td>\n",
       "      <td>0.072808</td>\n",
       "      <td>-0.052848</td>\n",
       "      <td>0.036295</td>\n",
       "      <td>0.000985</td>\n",
       "      <td>0.000289</td>\n",
       "      <td>0.003349</td>\n",
       "      <td>-0.001369</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.015681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender_M</th>\n",
       "      <td>0.050618</td>\n",
       "      <td>0.026327</td>\n",
       "      <td>-0.197594</td>\n",
       "      <td>0.021824</td>\n",
       "      <td>-0.011332</td>\n",
       "      <td>-0.072808</td>\n",
       "      <td>0.052848</td>\n",
       "      <td>-0.036295</td>\n",
       "      <td>-0.000985</td>\n",
       "      <td>-0.000289</td>\n",
       "      <td>-0.003349</td>\n",
       "      <td>0.001369</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.015681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>status_coded</th>\n",
       "      <td>0.011733</td>\n",
       "      <td>-0.019896</td>\n",
       "      <td>0.002527</td>\n",
       "      <td>-0.081115</td>\n",
       "      <td>-0.035099</td>\n",
       "      <td>0.063267</td>\n",
       "      <td>0.053033</td>\n",
       "      <td>0.150438</td>\n",
       "      <td>0.066751</td>\n",
       "      <td>0.007534</td>\n",
       "      <td>0.002545</td>\n",
       "      <td>0.008308</td>\n",
       "      <td>0.015681</td>\n",
       "      <td>-0.015681</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     age  participant_id  runner_rank   race_id    Season  \\\n",
       "age             1.000000       -0.270411    -0.216783 -0.010206  0.047769   \n",
       "participant_id -0.270411        1.000000    -0.194335  0.386143 -0.020922   \n",
       "runner_rank    -0.216783       -0.194335     1.000000  0.020117 -0.074137   \n",
       "race_id        -0.010206        0.386143     0.020117  1.000000 -0.058049   \n",
       "Season          0.047769       -0.020922    -0.074137 -0.058049  1.000000   \n",
       "Metro_area      0.018868        0.029178    -0.018915  0.130348 -0.229057   \n",
       "WL_SO          -0.043341       -0.089945     0.115371 -0.123373 -0.543905   \n",
       "Entry_fee       0.043721       -0.122077    -0.045335 -0.212501 -0.242692   \n",
       "PPM            -0.016771       -0.070901     0.113499  0.017266 -0.293994   \n",
       "Age_Rank       -0.007417       -0.005315    -0.003333 -0.015521 -0.004094   \n",
       "Gender_Rank     0.000602       -0.005174    -0.008166 -0.024019 -0.006021   \n",
       "Total_races     0.011360       -0.015240     0.007546 -0.029799  0.019240   \n",
       "gender_F       -0.050618       -0.026327     0.197594 -0.021824  0.011332   \n",
       "gender_M        0.050618        0.026327    -0.197594  0.021824 -0.011332   \n",
       "status_coded    0.011733       -0.019896     0.002527 -0.081115 -0.035099   \n",
       "\n",
       "                Metro_area     WL_SO  Entry_fee       PPM  Age_Rank  \\\n",
       "age               0.018868 -0.043341   0.043721 -0.016771 -0.007417   \n",
       "participant_id    0.029178 -0.089945  -0.122077 -0.070901 -0.005315   \n",
       "runner_rank      -0.018915  0.115371  -0.045335  0.113499 -0.003333   \n",
       "race_id           0.130348 -0.123373  -0.212501  0.017266 -0.015521   \n",
       "Season           -0.229057 -0.543905  -0.242692 -0.293994 -0.004094   \n",
       "Metro_area        1.000000 -0.292363   0.117692  0.406314 -0.010899   \n",
       "WL_SO            -0.292363  1.000000   0.413294  0.319025  0.028082   \n",
       "Entry_fee         0.117692  0.413294   1.000000  0.334784  0.001548   \n",
       "PPM               0.406314  0.319025   0.334784  1.000000  0.003491   \n",
       "Age_Rank         -0.010899  0.028082   0.001548  0.003491  1.000000   \n",
       "Gender_Rank      -0.017804  0.026839  -0.006640 -0.017046  0.766592   \n",
       "Total_races      -0.007776  0.006227  -0.006176  0.017571  0.177129   \n",
       "gender_F          0.072808 -0.052848   0.036295  0.000985  0.000289   \n",
       "gender_M         -0.072808  0.052848  -0.036295 -0.000985 -0.000289   \n",
       "status_coded      0.063267  0.053033   0.150438  0.066751  0.007534   \n",
       "\n",
       "                Gender_Rank  Total_races  gender_F  gender_M  status_coded  \n",
       "age                0.000602     0.011360 -0.050618  0.050618      0.011733  \n",
       "participant_id    -0.005174    -0.015240 -0.026327  0.026327     -0.019896  \n",
       "runner_rank       -0.008166     0.007546  0.197594 -0.197594      0.002527  \n",
       "race_id           -0.024019    -0.029799 -0.021824  0.021824     -0.081115  \n",
       "Season            -0.006021     0.019240  0.011332 -0.011332     -0.035099  \n",
       "Metro_area        -0.017804    -0.007776  0.072808 -0.072808      0.063267  \n",
       "WL_SO              0.026839     0.006227 -0.052848  0.052848      0.053033  \n",
       "Entry_fee         -0.006640    -0.006176  0.036295 -0.036295      0.150438  \n",
       "PPM               -0.017046     0.017571  0.000985 -0.000985      0.066751  \n",
       "Age_Rank           0.766592     0.177129  0.000289 -0.000289      0.007534  \n",
       "Gender_Rank        1.000000     0.157633  0.003349 -0.003349      0.002545  \n",
       "Total_races        0.157633     1.000000 -0.001369  0.001369      0.008308  \n",
       "gender_F           0.003349    -0.001369  1.000000 -1.000000      0.015681  \n",
       "gender_M          -0.003349     0.001369 -1.000000  1.000000     -0.015681  \n",
       "status_coded       0.002545     0.008308  0.015681 -0.015681      1.000000  "
      ]
     },
     "execution_count": 1183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fe4.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once adding gender dummies, it appears that gender in and of itself may not be a great predictor of race status. Appears to be ~75% male and 25% female particitation in these races."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = fe4.pop('status_coded')\n",
    "clean = fe4.drop(['gender', 'participant_id', 'race_name', 'race_id', 'Age_Rank', 'Gender_Rank', 'Total_races'\\\n",
    "                 , 'gender_M'], axis=1)\n",
    "X = clean\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 1185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LR(C=100)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predicted = model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20506065648496094"
      ]
     },
     "execution_count": 1187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(y_test, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -2.60655838e-04,  -1.53956285e-03,   7.57770170e-02,\n",
       "          4.64655688e-01,   2.70842412e-02,   1.61221998e+00,\n",
       "         -7.49635486e-02,  -7.51114810e-03]])"
      ]
     },
     "execution_count": 1188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49899198485487145"
      ]
     },
     "execution_count": 1189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = RFC(n_estimators=500, criterion='entropy', random_state=1, n_jobs=2)\n",
    "model2.fit(X_train, y_train)\n",
    "predicted2 = model2.predict_proba(X_test)\n",
    "log_loss(y_test, predicted2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1211,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20501420189126793"
      ]
     },
     "execution_count": 1211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3 = GBC(n_estimators=50, max_depth=4, learning_rate=0.1)\n",
    "model3.fit(X_train, y_train)\n",
    "predictions = model3.predict_proba(X_test)\n",
    "log_loss(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.60023586690070518"
      ]
     },
     "execution_count": 1198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "roc_auc_score(y_test, predicted[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.70605915019822652"
      ]
     },
     "execution_count": 1199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Random Forest\n",
    "roc_auc_score(y_test, predicted2[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.660563508156\n"
     ]
    }
   ],
   "source": [
    "#GBC\n",
    "fpr, tpr, thresholds = roc_curve(y_test, predictions[:,1])\n",
    "print auc(fpr, tpr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20869373865250765"
      ]
     },
     "execution_count": 1195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neighbor = knn(n_neighbors=1000, p=2, metric='minkowski')\n",
    "neighbor.fit(X_train, y_train)\n",
    "knn_predict = neighbor.predict_proba(X_test)\n",
    "log_loss(y_test, knn_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1049,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.67891741,  0.57597346,  0.56421275,  0.48059792,  0.63268156,\n",
       "         0.60716443,  0.5425034 ,  0.67692133,  0.54367356,  0.61506828]),\n",
       " array([ 0.71757322,  0.69535226,  0.70470052,  0.70064548,  0.67076853,\n",
       "         0.5811377 ,  0.64600634,  0.66231315,  0.60523932,  0.66183659]),\n",
       " array([ 0.68918919,  0.70879038,  0.67765464,  0.65591499,  0.63290805,\n",
       "         0.68350823,  0.68548996,  0.66978711,  0.62379209,  0.65140053]))"
      ]
     },
     "execution_count": 1049,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_cvscores = cross_val_score(estimator=model, X=X_train, y=y_train, cv=10, scoring='roc_auc')\n",
    "RF_cvscores = cross_val_score(estimator=model2, X=X_train, y=y_train, cv=10, scoring='roc_auc')\n",
    "GBC_cvscores = cross_val_score(estimator=model3, X=X_train, y=y_train, cv=10, scoring='roc_auc')\n",
    "LR_cvscores, RF_cvscores, GBC_cvscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1050,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.59177141044412729, 0.6645573110305556, 0.66784351620092086)"
      ]
     },
     "execution_count": 1050,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_cvscores.mean(), RF_cvscores.mean(), GBC_cvscores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 957,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-fold cross validation:\n",
      "ROC AUC: 0.63 (+/- 0.05) [Logistic Regression]\n",
      "ROC AUC: 0.68 (+/- 0.05) [Random Forest]\n",
      "ROC AUC: 0.68 (+/- 0.05) [Gradient Boost]\n"
     ]
    }
   ],
   "source": [
    "# clf1 = LR(C=10, random_state=0)\n",
    "# clf2 = RFC(n_estimators=500, criterion='entropy', random_state=1, n_jobs=2)\n",
    "# clf3 = GBC()\n",
    "# pipe1 = Pipeline([['sc', StandardScaler()], ['clf', clf1]])\n",
    "# pipe3 = Pipeline([['sc', StandardScaler()], ['clf', clf3]])\n",
    "# clf_labels = ['Logistic Regression', 'Random Forest', 'Gradient Boost']\n",
    "# print '10-fold cross validation:'\n",
    "# for clf, label in zip([pipe1, clf2, pipe3], clf_labels):\n",
    "#     scores = cross_val_score(estimator=clf, X=X_train, y=y_train, cv=10, scoring='roc_auc')\n",
    "#     print 'ROC AUC: %0.2f (+/- %0.2f) [%s]' % (scores.mean(), scores.std(), label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 955,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# lst = ['r', 'b']\n",
    "# new = ['r' if each == 1 else 'b' for each in y_test]\n",
    "# plt.scatter(X_test['age'], y_test, c=new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 866,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.199248924202\n",
      "0.557000588285\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000] }\n",
    "LR_GS = GridSearchCV(model, param_grid=param_grid)\n",
    "LR_GS.fit(X_train, y_train)\n",
    "LR_GS_pred = LR_GS.predict_proba(X_test)\n",
    "print log_loss(y_test, LR_GS_pred)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, LR_GS_pred[:,1], pos_label=1)\n",
    "print auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 861,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.332532940743\n",
      "0.713905530277\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\"max_depth\": [3, None],\n",
    "              \"max_features\": [1, 4, 8],\n",
    "              \"min_samples_split\": [1, 4, 8],\n",
    "              \"min_samples_leaf\": [1, 4, 8],\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "RF_GS = GridSearchCV(model2, param_grid=param_grid)\n",
    "RF_GS.fit(X_train, y_train)\n",
    "RF_GS_pred = RF_GS.predict_proba(X_test)\n",
    "print log_loss(y_test, RF_GS_pred)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, RF_GS_pred[:,1])\n",
    "print auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 867,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.212166156317\n",
      "0.658629776812\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'n_estimators':[100, 500, 1000],\n",
    "              'max_depth':[1,4,8], 'min_samples_split':[1,4,8], \"max_features\": [1, 4, 8],\n",
    "             'subsample':[0.6,0.7,0.75,0.8,0.85,0.9]}\n",
    "GBC_GS = GridSearchCV(model3, param_grid=param_grid)\n",
    "GBC_GS.fit(X_train, y_train)\n",
    "GBC_GS_pred = GBC_GS.predict_proba(X_test)\n",
    "print log_loss(y_test, GBC_GS_pred)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, GBC_GS_pred[:,1])\n",
    "print auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 872,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test, RF_GS_pred[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 904,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  9.74516667e-01,   2.54833333e-02],\n",
       "       [  9.67238095e-01,   3.27619048e-02],\n",
       "       [  9.98000000e-01,   2.00000000e-03],\n",
       "       ..., \n",
       "       [  9.78900000e-01,   2.11000000e-02],\n",
       "       [  9.99500000e-01,   5.00000000e-04],\n",
       "       [  9.94857143e-01,   5.14285714e-03]])"
      ]
     },
     "execution_count": 904,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_GS_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1072,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def modelfit(alg, X_train, y_train, X_test, y_test, performCV=True, printFeatureImportance=True, cv_folds=5):\n",
    "    #Fit the algorithm on the data\n",
    "    predictors = [x for x in X_train.columns if x not in y]\n",
    "    alg.fit(X_train, y_train)\n",
    "        \n",
    "    #Predict training set:\n",
    "    dtrain_predictions = alg.predict(X_test)\n",
    "    dtrain_predprob = alg.predict_proba(X_test)[:,1]\n",
    "    \n",
    "    #Perform cross-validation:\n",
    "    if performCV:\n",
    "        cv_score = cross_val_score(alg, X_train, y_train, cv=cv_folds, scoring='roc_auc')\n",
    "    \n",
    "    #Print model report:\n",
    "    print \"\\nModel Report: %s\" % alg\n",
    "    print \"Accuracy : %.4g\" % accuracy_score(y_test, dtrain_predictions)\n",
    "    print \"AUC Score (Train): %f\" % roc_auc_score(y_test, dtrain_predprob)\n",
    "    \n",
    "    if performCV:\n",
    "        print \"CV Score : Mean - %.7g | Std - %.7g | Min - %.7g | Max - %.7g\" % (np.mean(cv_score),np.std(cv_score),np.min(cv_score),np.max(cv_score))\n",
    "        \n",
    "    #Print Feature Importance:\n",
    "    if printFeatureImportance:\n",
    "        feat_imp = pd.Series(alg.feature_importances_, X_test.columns).sort_values(ascending=False)\n",
    "        feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "        plt.ylabel('Feature Importance Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1073,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Report: RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=2, oob_score=False, random_state=1,\n",
      "            verbose=0, warm_start=False)\n",
      "Accuracy : 0.9523\n",
      "AUC Score (Train): 0.677220\n",
      "CV Score : Mean - 0.6620223 | Std - 0.03623075 | Min - 0.6215499 | Max - 0.7223014\n",
      "\n",
      "Model Report: GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=100, presort='auto', random_state=None,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "Accuracy : 0.952\n",
      "AUC Score (Train): 0.653342\n",
      "CV Score : Mean - 0.6797614 | Std - 0.03185798 | Min - 0.6452019 | Max - 0.7315124\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtUAAAFDCAYAAAD1ZPKoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJGlAFtWSJEnSgCyqJUmSpAH9/7VSta3j0zjhAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x3c3f72e90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "models = [model2, model3]\n",
    "\n",
    "modelfit(model2, X_train, y_train, X_test, y_test)\n",
    "modelfit(model3, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1077,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=8,\n",
       "              max_features='sqrt', max_leaf_nodes=None,\n",
       "              min_impurity_split=1e-07, min_samples_leaf=50,\n",
       "              min_samples_split=50, min_weight_fraction_leaf=0.0,\n",
       "              n_estimators=100, presort='auto', random_state=10,\n",
       "              subsample=0.8, verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=False, n_jobs=4,\n",
       "       param_grid={'n_estimators': [20, 30, 40, 50, 60, 70, 80]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 1077,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test1 = {'n_estimators':range(20,81,10)}\n",
    "gsearch1 = GridSearchCV(estimator = GBC(learning_rate=0.1, min_samples_split=50,min_samples_leaf=50,max_depth=8,max_features='sqrt',subsample=0.8,random_state=10),\n",
    "                        param_grid = param_test1, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch1.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.649840565938\n"
     ]
    }
   ],
   "source": [
    "param_test2 = {'max_depth':range(5,16,2), 'min_samples_split':range(200,1001,200)}\n",
    "gsearch2 = GridSearchCV(estimator = GBC(learning_rate=0.1, n_estimators=20, max_features='sqrt', subsample=0.8, random_state=10), \n",
    "param_grid = param_test2, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch2.fit(X_train,y_train)\n",
    "gsearch2.grid_scores_, gsearch2.best_params_, gsearch2.best_score_\n",
    "psearch = gsearch2.predict_proba(X_test)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, psearch[:,1])\n",
    "print auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#modelfit(gsearch1, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1079,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([mean: 0.67064, std: 0.02891, params: {'n_estimators': 20},\n",
       "  mean: 0.66522, std: 0.03129, params: {'n_estimators': 30},\n",
       "  mean: 0.66365, std: 0.03181, params: {'n_estimators': 40},\n",
       "  mean: 0.66117, std: 0.03330, params: {'n_estimators': 50},\n",
       "  mean: 0.65608, std: 0.03523, params: {'n_estimators': 60},\n",
       "  mean: 0.66043, std: 0.03306, params: {'n_estimators': 70},\n",
       "  mean: 0.66434, std: 0.03163, params: {'n_estimators': 80}],\n",
       " {'n_estimators': 20},\n",
       " 0.6706365364910878)"
      ]
     },
     "execution_count": 1079,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1093,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([mean: 0.67949, std: 0.02647, params: {'min_samples_split': 1000, 'min_samples_leaf': 30},\n",
       "  mean: 0.68234, std: 0.02162, params: {'min_samples_split': 1200, 'min_samples_leaf': 30},\n",
       "  mean: 0.67251, std: 0.02539, params: {'min_samples_split': 1400, 'min_samples_leaf': 30},\n",
       "  mean: 0.66786, std: 0.02394, params: {'min_samples_split': 1600, 'min_samples_leaf': 30},\n",
       "  mean: 0.67317, std: 0.02511, params: {'min_samples_split': 1800, 'min_samples_leaf': 30},\n",
       "  mean: 0.67498, std: 0.02223, params: {'min_samples_split': 2000, 'min_samples_leaf': 30},\n",
       "  mean: 0.67854, std: 0.02783, params: {'min_samples_split': 1000, 'min_samples_leaf': 40},\n",
       "  mean: 0.68438, std: 0.02359, params: {'min_samples_split': 1200, 'min_samples_leaf': 40},\n",
       "  mean: 0.67213, std: 0.02466, params: {'min_samples_split': 1400, 'min_samples_leaf': 40},\n",
       "  mean: 0.66776, std: 0.02422, params: {'min_samples_split': 1600, 'min_samples_leaf': 40},\n",
       "  mean: 0.67471, std: 0.02442, params: {'min_samples_split': 1800, 'min_samples_leaf': 40},\n",
       "  mean: 0.67719, std: 0.02349, params: {'min_samples_split': 2000, 'min_samples_leaf': 40},\n",
       "  mean: 0.67741, std: 0.02783, params: {'min_samples_split': 1000, 'min_samples_leaf': 50},\n",
       "  mean: 0.68207, std: 0.02599, params: {'min_samples_split': 1200, 'min_samples_leaf': 50},\n",
       "  mean: 0.67769, std: 0.02812, params: {'min_samples_split': 1400, 'min_samples_leaf': 50},\n",
       "  mean: 0.66891, std: 0.02460, params: {'min_samples_split': 1600, 'min_samples_leaf': 50},\n",
       "  mean: 0.67628, std: 0.02688, params: {'min_samples_split': 1800, 'min_samples_leaf': 50},\n",
       "  mean: 0.67748, std: 0.02376, params: {'min_samples_split': 2000, 'min_samples_leaf': 50},\n",
       "  mean: 0.68240, std: 0.03072, params: {'min_samples_split': 1000, 'min_samples_leaf': 60},\n",
       "  mean: 0.68356, std: 0.02734, params: {'min_samples_split': 1200, 'min_samples_leaf': 60},\n",
       "  mean: 0.67829, std: 0.02853, params: {'min_samples_split': 1400, 'min_samples_leaf': 60},\n",
       "  mean: 0.67152, std: 0.02671, params: {'min_samples_split': 1600, 'min_samples_leaf': 60},\n",
       "  mean: 0.67684, std: 0.02757, params: {'min_samples_split': 1800, 'min_samples_leaf': 60},\n",
       "  mean: 0.67984, std: 0.02634, params: {'min_samples_split': 2000, 'min_samples_leaf': 60},\n",
       "  mean: 0.68382, std: 0.03008, params: {'min_samples_split': 1000, 'min_samples_leaf': 70},\n",
       "  mean: 0.68037, std: 0.02433, params: {'min_samples_split': 1200, 'min_samples_leaf': 70},\n",
       "  mean: 0.67807, std: 0.02887, params: {'min_samples_split': 1400, 'min_samples_leaf': 70},\n",
       "  mean: 0.67370, std: 0.02545, params: {'min_samples_split': 1600, 'min_samples_leaf': 70},\n",
       "  mean: 0.67693, std: 0.02823, params: {'min_samples_split': 1800, 'min_samples_leaf': 70},\n",
       "  mean: 0.67928, std: 0.02644, params: {'min_samples_split': 2000, 'min_samples_leaf': 70}],\n",
       " {'min_samples_leaf': 40, 'min_samples_split': 1200},\n",
       " 0.6843817039575235)"
      ]
     },
     "execution_count": 1093,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test3 = {'min_samples_split':range(1000,2100,200), 'min_samples_leaf':range(30,71,10)}\n",
    "gsearch3 = GridSearchCV(estimator = GBC(learning_rate=0.1, n_estimators=20,max_depth=5,max_features='sqrt', subsample=0.8, random_state=10), \n",
    "param_grid = param_test3, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch3.fit(X_train,y_train)\n",
    "gsearch3.grid_scores_, gsearch3.best_params_, gsearch3.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Report: GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=5,\n",
      "              max_features='sqrt', max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=40,\n",
      "              min_samples_split=1200, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=20, presort='auto', random_state=10,\n",
      "              subsample=0.8, verbose=0, warm_start=False)\n",
      "Accuracy : 0.9523\n",
      "AUC Score (Train): 0.644234\n",
      "CV Score : Mean - 0.6843817 | Std - 0.02358628 | Min - 0.6515409 | Max - 0.7114398\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtUAAAFDCAYAAAD1ZPKoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xvc7fWc9/HXe1ekKEJtoiKniUlIIsOmQTmPYxhMjIlx\nds8t3GOKGUxzj9wOY0ykKWPkEIkhOV3OOukgSpHScZMOkiT1uf/4/a7W2ntf+9qrvQ6/de31ej4e\n63Gt32+d3td37+u6Puu7vodUFZIkSZLW37KuA0iSJElLnUW1JEmSNCSLakmSJGlIFtWSJEnSkCyq\nJUmSpCFZVEuSJElDsqiWJEmShmRRLWnmJTkvye+S/CbJ1e3X5UM+5yOTXDCqjAO+5mFJ3jrJ11yb\nJAckOaLrHJI0KRt3HUCSpkABT6iqr4/wOdM+7/o9ONmoqm4YYZ6JSbJR1xkkadLsqZakRhY8meye\n5DtJrkhySpJH9t32V0l+3PZs/zTJ37TnNwO+ANy5v+d79Z7k1Xuzk/w8yeuTnAb8NsmyJHdK8qkk\nv0zysySvHOibSbZPcmOb8RdJfp1kvyS7JjktyeVJ3tt3/xcm+XaS9ya5sv2+Ht13+52SfLZ9nrOT\n/HXfbQck+WSSjyS5Engp8Cbg2e33f8pi7dXfFklel2RlkouS/FXf7ZsmeWf7qcIVSb6Z5JYD/hv9\nrH3NnyV5ziDtJ0k3lz3VkrQWSe4MfB54XlV9KcmewFFJ7l1VvwZWAo+vqvOS/BlwbJITqurUJHsD\nH6mq7fqeb6GXWb03ex9gb+DX7W2fAz4DPBu4K/CVJGdV1ZcH/DZ2A+4BPKJ9ri8CjwZuCZyS5BNV\n9a32vg8BPgHcHng68OkkO1TVlcDHgdOA5cBOwJeT/LSq5trHPhl4RlU9vy127wDsWFUv6Muy1vZq\nb18O3Aa4M/BY4FNJPlNVVwHvBP4E2L19nocANy72bwRcC7wbeFBV/TTJNsBWA7abJN0s9lRLUuPo\ntvf28iSfbs/9JfA/VfUlgKr6KnAS8Pj2+ItVdV57/VvAccCfDZnj3VV1cVVdBzwYuENVva2qbmhf\n60M0hfcgCnhrVf2hqr4CXAN8rKp+XVUXA98CHtB3/5VV9Z72tT4B/AR4QpK7AA8F9q+q66vqtDZH\nf8H8var6HECbfc0w626vPwD/2L7+F4HfAvdO825kX+BVVXVpNb5fVdezjn8j4AbgT5NsWlUrq+rM\nAdtOkm4Wi2pJajylqrZqL09rz20PPKuv2L4C2AO4E0CSvZN8rx0ScQVND/MdhsxxYd/17YFtV3v9\nNwJb34zn+2Xf9Wtpenn7j2/dd3zRao89n6bX+M7A5VX1u9Vu27bveJ2TMgdor19X1Y19x79r892B\npmf93AWedq3/Rm3eZwMvAy5J8rm2B1uSRs7hH5LUWGhsxgXAEVW13xp3Tm4BfIqmp/SzVXVjks/0\nPc9CkxSvATbrO77TAvfpf9wFwLlVNalCcNvVjrcDPgtcDGyVZPOquqbvtv4ifPXvd5XjAdprMZcB\nvwd2BH642m1r/TcCaIfJfLkdkvI24IM0Q2EkaaTsqZaktfsv4ElJHttOGty0nVB3Z+AW7eWytkDc\nm2Yc8LyVwO2TbNF37lTg8Ulul2bJvlev4/VPAK5uJy9ummSjJPdNsuuA+QcpWPttneSVSTZO8kzg\nPjRDKy4Evgu8I8ktk+wMvBj4yCLPtRLYIb2B5Otqr7WqqgIOAw5uJ0wuaycnbsIi/0ZJtk7y5DQT\nR6+nGU6yJFdUkTT9LKolaS1L37XF5FNoVrL4Fc2Qh78DllXVb4FXAZ9McjnNOOfP9j32J8DHgHPb\nYQnLaYrQ04HzgGOBIxfL0Q6FeCKwC/BzmqEcHwS2YDCL9h4vcHw8cE+anuF/BJ7eTlIEeA5wN5pe\n66OAN69jCcJP0hT1v05yUtter2Yt7TVA/r+j6aU+kWYS5z/T/Dus9d+ovbyOpkf9Mpoe6pet4zUl\nab2k6QAY4wskewH/j+aX26FVddBqtz8X2L89vBr426o6vb3tPOAq4Ebg+qrabaxhJWlGJXkh8OKq\ncmiEJK2HsY6pTrIMeB+wJ03vxolJPltVZ/Xd7VzgEVV1VVuAH0KzZBI0xfSKqrpinDklSZKkYYx7\n+MduwDlVdX679NGRNB/T3aRdFumq9vD7rDpRJhPIKEmSJA1l3AXrtqy6zNKFrDm7vN9f02xMMK9o\nZm2fmOQlY8gnSQKq6nCHfkjS+puaJfWSPIpmcf+H953eo6ouSXJHmuL6zKr6djcJJUmSpIWNu6i+\niGYt03l3Yc3NBWiXZzoE2Kt//HRVXdJ+/VW7nuluwBpFdZLxzraUJEmSgKpacLnScQ//OBG4R5Lt\n24X/9wGO6b9Dku1olmd6flX9rO/8Zklu3V7fnGY90zPW9kJV1enlgAMO6DzDtFxsC9vCtrAtbAvb\nwrawLTbEtljMWHuqq+qGJK8AjqO3pN6ZSfZrbq5DgDcDWwHvbzcJmF86bxvgM20v9MbAR6vquHHm\nlSRJktbH2MdUV9WxwL1XO/cffddfAqwxCbGqfk6z4YEkSZI01VyubkRWrFjRdYSpYVv02BY9tkWP\nbdFjW/TYFj22RY9t0TPtbTH2HRUnIUltCN+HJEmSplcSqqOJipIkSdIGz6JakiRJGpJFtSRJkjQk\ni2pJkiRpSBbVkiRJ0pAsqiVJkqQhWVRLkiRJQ7KoliRJkoZkUS1JkiQNyaJakiRJGpJFtSRJkjQk\ni2pJkiRpSBbVkiRJ0pAsqiVJkqQhWVRLkiRJQ7KoliRJkoZkUS1JkiQNyaJakiRJGpJFtSRJkjQk\ni2pJkiRpSBbVkiRJ0pAsqiVJkqQhWVRLkiRJQ7KoliRJkoZkUS1JkiQNyaJakiRJGpJFtSRJkjQk\ni2pJkiRpSBbVkiRJ0pAsqoHly3cgSeeX5ct36LopJEmStB5SVV1nGFqSGub7SAJMQzuEDeHfQ5Ik\naUOUhKrKQrfZUy1JkiQNyaJakiRJGpJFtSRJkjSksRfVSfZKclaSs5Psv8Dtz01yWnv5dpKdB32s\nJEmSNA3GOlExyTLgbGBP4GLgRGCfqjqr7z67A2dW1VVJ9gIOrKrdB3ls33M4UVGSJElj1eVExd2A\nc6rq/Kq6HjgSeEr/Harq+1V1VXv4fWDbQR8rSZIkTYNxF9XbAhf0HV9Ir2heyF8DX1zPx2oEXLNb\nkiTp5tu46wDzkjwK2Bd4+Po8/sADD7zp+ooVK1ixYsVIcs2alSvPZxqGwqxcueAnK5IkSRMzNzfH\n3NzcQPcd95jq3WnGSO/VHr8BqKo6aLX77QwcBexVVT+7OY9tb3NM9agS2BaSJEkL6nJM9YnAPZJs\nn+QWwD7AMauF246moH7+fEE96GMlSZKkaTDW4R9VdUOSVwDH0RTwh1bVmUn2a26uQ4A3A1sB70/T\nTXp9Ve22tseOM6/Ub/nyHdrhMN3aZpvtufTS87qOIUmSFjHw8I8km1XV78acZ704/GOECWyLXgLb\nQpIk9Rlq+EeShyX5MXBWe3z/JO8fcUZJkiRpyRpkTPW7gMcBvwaoqtOAR4wzlCRJkrSUDDRRsaou\nWO3UDWPIIkmSJC1Jg0xUvCDJw4BKsgnwasAJg5IkSVJrkJ7qlwIvp9nN8CJgl/ZYkiRJEuvoqU6y\nEc360c+bUB5JkiRpyVm0p7qqbgCeO6EskiRJ0pK0znWqk7wL2AT4OHDN/Pmq+sF4ow3OdapHmMC2\n6CWwLSRJUp/F1qkepKj++gKnq6oePYpwo2BRPcIEtkUvgW0hSZL6DFVULwUW1SNMYFv0EtgWkiSp\nz7A7Km6Z5OAkJ7WXdybZcvQxJUmSpKVpkCX1PgxcDTyrvfwGOGycoSRJkqSlZJAx1adW1S7rOtcl\nh3+MMIFt0UtgW0iSpD5DDf8Ark3y8L4n2wO4dlThJEmSpKVukG3KXwYc3jeO+grgr8aWSJIkSVpi\nBl79I8kWAFX1m7EmWg8O/xhhAtuil8C2kCRJfYZd/ePtSW5bVb+pqt8kuV2Sfxp9TEmSJGlpGmRM\n9d5VdeX8QVVdATx+fJEkSZKkpWWQonqjJLecP0hyK+CWi9xfkiRJmimDTFT8KPDVJPNrU+8LHD6+\nSJIkSdLSMtBExSR7AX9OM2vrK1X1pXEHuzmcqDjCBLZFL4FtIUmS+iw2UfHmrP5xe+ARwC+q6uQR\n5huaRfUIE9gWvQS2hSRJ6rNeq38k+XyS+7XX7wScAbwI+EiS14wlqSRJkrQELTZR8W5VdUZ7fV/g\ny1X1JOAhNMW1JEmSJBYvqq/vu74n8AWAqroauHGcoSRJkqSlZLHVPy5I8krgQuCBwLFw05J6m0wg\nmyRJkrQkLNZT/WLgvsBfAc/u2wBmd+CwtT1IkiRJmjUDr/4xzVz9Y4QJbIteAttCkiT1Wa/VPyRJ\nkiQNxqJakiRJGpJFtSRJkjSkdRbVSe6V5KtJzmiPd07y9+OPJkmSJC0Ng/RUfxB4I+261VV1OrDP\nOENJkiRJS8kgRfVmVXXCauf+OI4wkiRJ0lI0SFF9WZIdadcWS/IM4JKxppIkSZKWkEGK6pcD/wHc\nJ8lFwGuAlw36Akn2SnJWkrOT7L/A7fdO8t0kv0/yutVuOy/JaUlOSbJ6b7kkSZI0FQbe/CXJ5sCy\nqrp64CdPlgFnA3sCFwMnAvtU1Vl997kDsD3wVOCKqjq477ZzgQdV1RXreB03fxlVAtuil8C2kCRJ\nfYba/CXJ25Pctqquqaqrk9wuyT8N+Nq7AedU1flVdT1wJPCU/jtU1WVVdTILj9POIBklSZKkLg1S\nsO5dVVfOH7S9xo8f8Pm3BS7oO76wPTeoAr6c5MQkL7kZj5MkSZImZuMB7rNRkltW1XUASW4F3HK8\nsW6yR1VdkuSONMX1mVX17Qm9tiRJkjSQQYrqjwJfTXJYe7wvcPiAz38RsF3f8V3acwOpqkvar79K\n8hma4SQLFtUHHnjgTddXrFjBihUrBn0ZSZIkaQ1zc3PMzc0NdN+BJiom2ZtmsiHAl6vqSwM9ebIR\n8JP2sZcAJwDPqaozF7jvAcBvq+qd7fFmNBMjf9tOkjwOeEtVHbfAY52oOKoEtkUvgW0hSZL6LDZR\nceDVP4Z48b2Ad9OM3z60qv45yX5AVdUhSbYBTgJuA9wI/BbYCbgj8BmaqmZj4KNV9c9reQ2L6lEl\nsC16CWwLSZLUZ6iiOsnTgIOArWlW4whNQbzFqIOuL4vqESawLXoJbAtJktRn2KL6p8CTFhqyMS0s\nqkeYwLboJbAtJElSn6HWqQZWTnNBLUmSJHVtkNU/TkryceBo4Lr5k1X16bGlkiRJkpaQQYrqLYDf\nAY/tO1eARbUkSZLEBFb/mATHVI8wgW3RS2BbSJKkPouNqV5nT3WSTYEXA/cFNp0/X1UvGllCSZIk\naQkbZKLiR4DlwOOAb9Dsinj1OENJkiRJS8kgS+qdUlUPSHJ6Ve2cZBPgW1W1+2QirpvDP0aYwLbo\nJbAtJElSn2GX1Lu+/XplkvsBW9JsBCNJkiSJwVb/OCTJ7YC/B44Bbg28eaypJEmSpCVkkOEfd6uq\nn6/rXJcc/jHCBLZFL4FtIUmS+gw7/OOoBc59arhIkiRJ0oZjrcM/ktyHZhm9LZM8re+mLehbWk+S\nJEmadYuNqb438ETgtsCT+s5fDbxknKEkSZKkpWTRMdVJNgL2r6q3Ty7SzeeY6hEmsC16CWwLSZLU\nZ73HVFfVDcBTx5JKkiRJ2kAMsvrHu4BNgI8D18yfr6ofjDfa4OypHmEC26KXwLaQJEl9FuupHqSo\n/voCp6uqHj2KcKNgUT3CBLZFL4FtIUmS+gxVVC8FFtUjTGBb9BLYFpIkqc9Q61Qn2TLJwUlOai/v\nTLLl6GNKkiRJS9Mgm798mGYZvWe1l98Ah40zlCRJkrSUDDKm+tSq2mVd57rk8I8RJrAteglsC0mS\n1GfYbcqvTfLwvifbA7h2VOEkSZKkpW6xHRXnvQw4vB1HHeBy4IVjTSVJkiQtIQOv/pFkC4Cq+s1Y\nE60Hh3+MMIFt0UtgW0iSpD7Drv5x+yTvAeaAryd5d5LbjzijJEmStGQNMqb6SOBXwNOBZ7TXPz7O\nUJIkSdJSMsjqH2dU1f1WO/fDqvrTsSa7GRz+McIEtkUvgW0hSZL6DLv6x3FJ9kmyrL08C/jSaCNK\nkiRJS9cgPdVXA5sDN7anlgHXtNerqrYYX7zB2FM9wgS2RS+BbSFJkvos1lO9ziX1quo2o48kSZIk\nbTgGWaeaJDsDO/Tfv6o+PaZMkiRJ0pKyzqI6yYeBnYEf0RsCUoBFtSRJksRgPdW7V9VOY08iSZIk\nLVGDrP7xvSQW1ZIkSdJaDNJTfQRNYX0pcB0QmlU/dh5rMkmSJGmJGKSn+lDg+cBewJOAJ7ZfB5Jk\nryRnJTk7yf4L3H7vJN9N8vskr7s5j5UkSZKmwSDrVH+vqh66Xk+eLAPOBvYELgZOBPapqrP67nMH\nYHvgqcAVVXXwoI/tew7XqR5VAtuil8C2kCRJfYZapxo4Jcl/A5+jGf4BDLyk3m7AOVV1fhvkSOAp\nwE2FcVVdBlyW5Ik397GSJmP58h1YufL8rmOwzTbbc+ml53UdQ5KkNQxSVN+Kpph+bN+5QZfU2xa4\noO/4QppieRDDPFbSCDUFdfe95StXLtg5IElS5wbZUXHfSQSRJEmSlqq1FtVJ3ssiXVNV9aoBnv8i\nYLu+47u05wZxsx574IEH3nR9xYoVrFixYsCXkSRJktY0NzfH3NzcQPdd60TFJC9c7IFVdfg6nzzZ\nCPgJzWTDS4ATgOdU1ZkL3PcA4LdV9c71eKwTFUeVwLboJbAteglsC0mS1m+i4iBF87pU1Q1JXgEc\nR7N836FVdWaS/Zqb65Ak2wAnAbcBbkzyamCnqvrtQo8dNpMkSZI0autcUm8psKd6hAlsi14C26KX\nwLaQJGnRnupBNn+RJEmStAiLakmSJGlI6yyqk9wryVeTnNEe75zk78cfTZIkSVoaBump/iDwRuB6\ngKo6HdhnnKEkSZKkpWSQonqzqjphtXN/HEcYSZIkaSkapKi+LMmOtFP/kzyDZt1oSZIkSQywTTnw\ncuAQ4D5JLgJ+DjxvrKkkSZKkJWTRojrJMmDXqvrzJJsDy6rq6slEkyRJkpaGRYd/VNWNwOvb69dY\nUEuSJElrGmRM9VeS/F2SuybZav4y9mSSJEnSErHObcqT/HyB01VVdx9PpJvPbcpHmMC26CWwLXoJ\nbAtJkhbdpnydExWr6m6jjyRJkiRtONZZVCd5wULnq+qI0ceRJEmSlp5BltR7cN/1TYE9gR8AFtWS\nJEkSgw3/eGX/cZLbAkeOLZEkSZK0xAyy+sfqrgEcZy1JkiS1BhlT/Tl60/6XATsBnxxnKEmSJGkp\nGWRJvUf2Hf4ROL+qLhxrqpvJJfVGmMC26CWwLXoJbIubLF++AytXnt9pBoBtttmeSy89r+sYkjRT\nFltSb5Ci+qCq2n9d57pkUT3CBLZFL4Ft0UtgW/QS2BaSNLMWK6oHGVP9mAXO7T1cJEmSJGnDsdYx\n1UleBvwtcPckp/fddBvgO+MOJkmSJC0Vax3+kWRL4HbAO4A39N10dVVdPoFsA3P4xwgT2Ba9BLZF\nL4Ft0UtgW0jSzBpqTHXfk2xNs/kLAFX1i9HEG55F9QgT2Ba9BLZFL4Ft0UtgW0jSzBpqTHWSJyU5\nB/g58A3gPOCLI00oSZIkLWGDTFT8J2B34OyquhvNNuXfH2sqSZIkaQkZpKi+vqp+DSxLsqyqvg7s\nOuZckiRJ0pKxzh0VgSuT3Br4FvDRJL+k2apckiRJEoNt/rI5cC1Nr/bzgC2Bj7a911PBiYojTGBb\n9BLYFr0EtkUvgW0hSTNrsYmK6+yprqprkmwP3LOqDk+yGbDRqENKkpYWt2yXpJ5BVv94CfAp4D/a\nU9sCR48zlCRp+jUFdXV+mYbCfvnyHUjS+WX58h26bgppZg0y/ONUYDfg+Kp6QHvuh1X1pxPINxCH\nf4wwgW3RS2Bb9BLYFr0EtkUvgW3RS2BbSDNhqHWqgeuq6g99T7Yx0/GbQ5IkSZoKgxTV30jyJuBW\nSR4DfBL43HhjSZIkSUvHIMM/lgEvBh4LBPgS8KGhxluMmMM/RpjAtuglsC16CWyLXgLbopfAtugl\nsC2kmbDY8I+1FtVJtquqX4w12YhYVI8wgW3RS2Bb9BLYFr0EtkUvgW3RS2BbSDNhfcdU37TCR5Kj\nRp5KkiRJ2kAsVlT3V+F3X98XSLJXkrOSnJ1k/7Xc5z1JzklyapIH9J0/L8lpSU5JcsL6ZpAkSZLG\nabHNX2ot1wfWjsd+H7AncDFwYpLPVtVZfffZG9ixqu6Z5CHAvwO7tzffCKyoqivW5/UlSZKkSVis\nqL5/kt/Q9Fjfqr1Oe1xVtcUAz78bcE5VnQ+Q5EjgKcBZffd5CnAEzZMen2TLJNtU1cr2tQZZoUSS\nJEnqzFqL6qoaxVbk2wIX9B1fSFNoL3afi9pzK2l6yL+c5AbgkKr64AgySZIkSSO1WE/1NNijqi5J\nckea4vrMqvr2Qnc88MADb7q+YsUKVqxYMZmEkiTpJsuX7zAVW8dvs832XHrpeV3H0BI3NzfH3Nzc\nQPdd5zrVw0iyO3BgVe3VHr+BZujIQX33+QDw9ar6eHt8FvDIdvhH/3MdAFxdVQcv8DouqTeqBLZF\nL4Ft0UtgW/QS2Ba9BLZFL4Ft0UtgW2gDNuw25cM4EbhHku2T3ALYBzhmtfscA7wAbirCr6yqlUk2\nS3Lr9vzmNJvPnDHmvJIkSdLNNtbhH1V1Q5JXAMfRFPCHVtWZSfZrbq5DquoLSR6f5KfANcC+7cO3\nAT6TpNqcH62q48aZV5IkSVofYx3+MSkO/xhhAtuil8C26CWwLXoJbIteAtuil8C26CWwLbQB63L4\nhyRJkrTBs6iWJEmShmRRLUmSJA3JolqSJEkakkW1JEmSNCSLakmSJGlIFtWSJEnSkCyqJUmSpCFZ\nVEuSJI3B8uU7kKTTy/LlO3TdDDPDHRVx96dVEtgWvQS2RS+BbdFLYFv0EtgWvQS2RS+BbdFLMBVt\n0X07bEjcUVGSJEkaI4tqSZIkaUgW1ZIkSdKQLKolSZKkIVlUS5IkSUOyqJYkSZKGZFEtSZIkDcmi\nWpIkSRqSRbUkSZI0JItqSZIkaUgW1ZIkSdKQLKolSZKkIVlUS5IkSUOyqJYkSZKGZFEtSZIkDcmi\nWpIkSRqSRbUkSZI0JItqSZIkaUgW1ZIkSdKQLKolSZKkIVlUS5IkSUOyqJYkSZKGZFEtSZIkDcmi\nWpIkSRqSRbUkSZI0pLEX1Un2SnJWkrOT7L+W+7wnyTlJTk2yy815rCRJktS1sRbVSZYB7wMeB9wX\neE6S+6x2n72BHavqnsB+wAcGfex0mes6wBSZ6zrAFJnrOsAUmes6wBSZ6zrAFJnrOsAUmes6wBSZ\n6zrAFJnrOsDUmJub6zrCosbdU70bcE5VnV9V1wNHAk9Z7T5PAY4AqKrjgS2TbDPgY6fIXNcBpshc\n1wGmyFzXAabIXNcBpshc1wGmyFzXAabIXNcBpshc1wGmyFzXAabGrBfV2wIX9B1f2J4b5D6DPFaS\nJEnq3DROVEzXASRJkjQ6y5fvQJKhLm95y1uGevzy5TuM9XtMVY3vyZPdgQOraq/2+A1AVdVBfff5\nAPD1qvp4e3wW8Ejgbut6bN9zjO+bkCRJklpVtWAH8MZjft0TgXsk2R64BNgHeM5q9zkGeDnw8bYI\nv7KqVia5bIDHAmv/5iRJkqRJGGtRXVU3JHkFcBzNUJNDq+rMJPs1N9chVfWFJI9P8lPgGmDfxR47\nzrySJEnS+hjr8A9JkiRpFkzjREVJkiRpSbGolqQxS7JDklu01x+e5G+TbNF1LknS6FhUayTanTFX\nP/fSLrJIU+hooJLsCBwG3BP4724jdSfJixc4989dZOlSkq0WOHe3LrJMiySbdZ1BWl/jXv1jg5Tk\nmMVur6onTyrLFHlzkuuq6msASV4PPIp22/lZk2RbYHv6fsaq6pvdJepOkvsBOwGbzp+rqiO6S9SJ\nG6vq+iRPA95bVe9JckrXoTr09CS/r6qPAiT5N/r+f8yQzyXZu6p+A5BkJ+ATwP26jTV5SR4GfAi4\nNbBdkvsD+1XV33abbPLa35mvp/m9CfAj4J1VdXp3qSYvydur6k3t9cdU1Ze7zrQuFtXr56E0uz1+\nDDgeN6wBeDLw+ST/G9gLuA9Tva38+CQ5CHg28GPghvZ0ATNXVCc5AFhB88fhC8DewLeBWSuq/5jk\nmcDzgae25zbpME/Xng4ck+RGmt8XV1bVGr3XM+DtNIX1E4B70/xcPK/bSJ15F/A4mmV2qarTkjyi\n20iTl+QpwL8C72i/AuwKHJXk76rqs52Fm7y9gDe11w8CLKo3UMuBx9Csm/1c4H+Aj1XVjzpN1aGq\nuizJk4GvACcDz6jZXVrmqcC9q+q6roNMgWcA9wdOqap9k2wD/FfHmbrwIuBvgX+pqnPbj/g/1nGm\niVttuMNf0wyL+Q7wliRbVdXl3STrRlX9T5JNaJaOvQ3wF1V1dsexOlNVFySr9FHdsLb7bsDeCjym\nqs7rO3d6kq8Bn20vmlIW1euhqm4AjgWOTXJLmuJ6Lslbqup93aabrCRX0/TCzrsFcHfgGUmqqmZx\nMta5NL2QFtVwbVXdmOSP7cS8XwJ37TrUpFXVGUleA2zXHv8ceFu3qTpxMs3vi/R9fUJ7KZrfHRu8\nJO9l1d+bWwI/A16RhKp6VTfJOnVBOwSk2jcarwZmcW+KjVcrqAGoqvPadpklWyd5Hc3vifnrN6mq\ng7uJtXYW1eupLaafQFNQ7wC8B/hMl5m6UFW36TrDFPodcGqSr9JXWM/oH8qTktwW+CBNQfVb4Hvd\nRpq89uP9g2nedN4tyS7AAVX1F90mm6yqmulJeH1OWu345E5STJeXAu8GtgUuoum9f3mnibrxxyTb\nVdUv+k+2u0v/saNMXfkgzSc4q1+fWm7+sh6SHEEzkeQLwJFVdUbHkaaCk/MaSV640PmqOnzSWaZJ\nkh2ALWbVNIk0AAAUQElEQVRtsg1AkpOBPYGvV9UD2nM/rKo/7TZZd9peyR1Y9ffFrI21l1aR5KnA\nv9CMt59/s7Ur8AZg/6o6uqts0yrJG6vqHV3nAIvq9dJOrrmm79R8I4Zm+/WZG/Kwtsl5M7oSCu2a\nxPdqD39SVdd3macraQZIPg+4e1W9Ncl2wPKqOqHjaBOV5PtVtXuSU/qK6tOraueus3UhyUeAHYFT\nWfX3xUx9mpNkD+BAep0R839DZmIYTL8k71ng9FXASTM2OY925ZP/Bdy3PTW/+sdp3aWaXkl+UFUP\n7DoHOPxjvVSV63uvycl5rSQrgMOB82j+SN41yQtnsdceeD9wI/Bomgk4VwNHAQ/uMlQHzkzyLGBZ\nO0nxVcD3O87UpV2BnWZ4MvO8Q4HX0vRIzuKkvH6b0qwa9cn2+OnAz4H7J3lUVb2ms2QT1hbPL5g/\nTnI74MruEk29qVmBzaJ6PSTZlGb81z2A04EPV9WsjXVanZPzet4JPLaqfgKQ5F40Kz08qNNU3XhI\nVT1wfk3mqrpifmfBGfMK4B9o3mB8GvgS8H86TdStM2hWUbqk6yAdu6qqvth1iCmxM7BHuxAASf4d\n+BbwcOCHXQabpCT/AHyiqs5q5259EdiFZqz1c6vqK90mnEpT8+bconr9HA5cT/MD/3iaj2he3Wmi\n7jk5r2eT+YIaoKrOnsFZ2/OuT7IR7S+9JHekKSxnSlVdA+zfXgR3AH6c5ARW/X0xa8PFvp7k/9K8\n0epvhx90F6kzt6PZ+OWq9nhzYKuquiHJLHXWPBv4x/b6C2l2vr4jzXDCw2mWrdWq7Kle4naan2CU\n5FBgpsaHrsUx7UXNihcforce81+y5mz/WTG/Ks7WSd5Gs27133cbafKSHAvsU1VXtse3A/6rqp7Q\nbbLOHNh1gCnxkPbrrn3nima41Kz5F5qOmTmaIukRwNuTbM5sFZJ/6BsW9TiaPTBuoBlCNnM1W9sp\n86qqetcid/vkIrdNlBMV18Pqg+KnaZC8utd+ZPdymo8toflE4/2zOt48yX1oVr4I8NWqmrm1Z/sn\nKC52TpplSe5Ms+vomTS91hfO2lyUJN+n2RhpJfAT4EHtuvYkOauq7tNlvi4kOaGqdus6xyBm7l3P\niNw/yW/ofeRwq77jWV39454026ruRDPhBIBZnMXeFs8HAwe3O8jdZRYL6raH4UftH4Gzus7TsRuT\n3KWqLgRoV0GZWUl2B94L/AnN2t0bAdfM6O/OJ9AMIez/vfnW7hJ1I8lf0wyjvAvNqjC706xpP2u9\n9q8GPkUz5ONdfQX144FTugzWoe8keR/wcfpWXpvGYVIW1euhqjbqOsMUOgw4AHgX8ChgX5qxYDOn\n/fjyyTQ/XycDv0zy3ap6bafBJqwdC/mThTYymEH/QPOH4Ws0b75XAC/rNFG33gfsQ/Ox7a40Kx3c\na9FHbICSfADYjOZ35odohkfN6nDCV9OsCvT9qnpU+wnX2zvONHFVdTzNKiirn/8Czd4YQLMfwgzt\nfbBL+7X/zeZUDpNy+Md6cPWPNSU5uaoe1L+hxfy5rrNN2vzH+m3Py12r6oBZXZM4yTeBB9AUCv09\nDLM2IY0k2wAPbQ+/W1W/7DJPl5KcVFW79v9czOJwmPnvv+/rrYEvVtWfdZ1t0pKcWFUPTnIqzapB\n1yX5UVXdd50PnkEOO51O9lSvH1f/WNN1SZYB5yR5Bc02s7fuOFNXNk5yJ+BZzPayaQBv7jrAFPk9\n8Auaj/nvkeQeVfXdjjN15Xft0oqnJvkXmqX1ZvGTrWvbr79rxxP/GrhTh3m6dGGS2wJHA19OcgVw\nfseZptnUrHgxbm2HxNuBO1fV3kl2Ah5aVYd2HG0NFtXrx9U/1vRqmo8xX0WzHNCjaJYDmkVvpVmH\n+NtVdWKSuwPndJypE1X1ja4zTIMkL6LZIW1bmjV3H0yz+cuKDmN16fk0RfQraDY/uSvNZh+z5vNt\nIfl/gR/QfKT9oW4jdaOq/qK9emCSrwNbAsd2GGnazdIwg/+kGWI630l1Ns346qkrqh3+sR5c/WNV\n7YS0g6rq77rOounihLRGkh8CuwHfq6pdktwXeGtVzWIhuaAke1TVd7rO0ZV21aBNq+qqdd5ZM2+W\nhkv1DQ266XtOcmpV7bKux06aPdXrZ371D2g+gpnp1T/aCWkPX/c9Z0M75v7FrDmj/0WdheqOE9Ia\nv6+qa5OQ5BZV9aMk9+461KS1b8CfRdNjf2xVnZHkicCbgFvRjL+fSe0Y4kckeX1VPabrPJo+SZ5e\nVUe1h7P0BvSaJLent4nY7vQ2CZoqFtXrwdU/FnRKkmNoiqf+CWmf7i5SZz5Cs4Tc42iGgjyPZt3V\nmVRVP02yUbuBwWHtluVv7DrXhF3Sfsz/OeBLSS4HLuw4UxcOpRnqcQLwniQX07zZekNVHd1psglK\n8mjgA8CdacYQH0Tz8XaAt3UYTdPtXcBRAFX1io6zTNLraDaX2zHJd2iWG3xGt5EW5vAPjUSSwxY4\nXbPYO9u3+sf8jP5NgG9V1e5dZ5u0dvWPP6cZJ3opzYS0v6qq+3carENJ9qQZL/o/s7Z+eZIzgJ2r\n6sb2E51LgR2r6tcdR5uo9o3la2nWYd6bZvfVN1TV+zoNpqmW5IKqumvXObrQ7iZ5b5o3nj+pqus7\njrQge6o1ElW172K3J3ljVb1jUnk6Nv/DfmWS+9EUDlt3mKdLMz8hrR3ycPr80mBV9dWOI3XpD1V1\nI0BV/T7JubNWULeqquba60cnuciCWgOYqV7QJE9by033SjKVn4RbVGtSnkmz4+IsOCTJ7WiWkzuG\nZmnBf+g2Ujeqan5JrN8Db1n99iRHbeiT9do5B+cm2baqLuo6T8fuk+T09npoPs49nd58lFlZy/22\nqxUMG/cfT2OxoMloJzUvVDwH2GbCcbr2pPbr1sDDgK+1x48CvgtM3c+Jwz80EbM0U1mDm5X/F+0S\nYQ+i+bi/f87B2npiNkhJtl/s9r43YRu0tQyXmzeTw+bUSPJamkmIl9P71PMms/Iz0i/JccALq+qS\n9vhOwH9W1eO6TbYme6o1KTPz7m0pLVQ/BWbl/8U/dR1gGgxaECT5XlU9dN33XJrWNVxu3oxtRa3G\ntsD/o9mq/Ic0BfZ3aXZhvbzLYB2663xB3VoJbNdVmMXYU62JmJUeSYAkX6RdqL6q7t9OsDhlfsMg\n9cz6Gu/zkny7qlyWsjVLvy8W48/H7Gp3HN2VZtjDQ9vLlVW1U6fBOpDkfcA9gY+1p54N/LSqXtld\nqoXN4rawGrEkG7UfWS3mkxMJMx3uUFWfAOYnZP0RuKHbSFNrZrbaXYfNuw4wZeztafjzMbtuBWxB\ns1LQlsDFwPGdJupIu3zgfwD3by+HTGNBDQ7/0Ai0E7GeQ7OG5tru8/YJRuraklmofhLaHpf5DV9W\nXwpp/w4iTSOLSC3E/xczJskhNBuHXU1TRH8XOLiqrug0WMfaybtTNzFxdRbVGpXvtB/RfJxVJ2L9\noLtInVkyC9WPW5IVwOHAeTS9bndtx4l+E6CqjusunaaYPbQN22H2bAfcEjgHuIhmk6grO03UsXZl\nnINoVgEJU7x7tWOqNRLt6garq6p69MTDdCTJg4ELqurSdhz1fjRrMv8Y+IdZnGSS5GTguVX1k/b4\nXsDHqupB3SabLrM0hrhdt/srVfWoRe5zv6o6Y4KxplKS983YznkCkoSmt/ph7eV+NKuBfK+qDugy\nWxeS/BR4UlVN/c7EFtXSiCT5AfDnVXV5kkcARwKvBHYB/qSqZq63en5XyXWdm3VJ7l9Vp3WdY1KS\nfBV4WlXN7LAocKUgLS7JXYA9aArrJwK3r6rbdptq8pJ8p6r26DrHICyqNRL+cYAkp81vv53k34Bf\nVdWB7fGpVbVLl/m6kOTDNBM2/6s99Txgo1lZhzfJFax9I4eqqq0mHGkqJPks8ADgy6w6XOxVnYXq\ngCsFaXVJXkWvh/p62uX02ssP53cknSVJ3g0sB44Grps/P42bJDmmWqPyn7R/HNrjs2nGV89MUQ1s\nlGTjdrWPPYG/6bttVn/WXga8HJgvlr4FvL+7OBN3h64DTKklMeloAu5QVZ9I8kZoVgpK4kpBs20H\nmtWyXrva2syzbAvgd8Bj+84VU/g7ZFb/0Gv0/OPQrKH5jSSXAdfSFJAkuQczuPpHO3b2w1X1PODg\nrvN0oapW+RlIshWwad+piyebaDpU1eFJbgVsNz/efka5UpBWUVWv6zrDtBl0s6Rp4DrVGpWZ/+NQ\nVW8D/hdNr/3Dqze2ahnN2OqZ0haU27dL6s20JE9IcjbNTP7j269f6zZVd5I8CTgVOLY93iXJMd2m\n6sTqKwUdwQz+rpAWk+ReSb6a5Iz2eOckf991roU4plojkeSBwHtpZimfQbuMXFWd3mkwdSrJEcCf\n0BQO/WNnZ6rnOsmpwGOA46rqAUkeAzyrql7ScbROtKvCPBqYm1/1JMkZVXW/bpNNXjuO+t404+xX\nX8ddmnlJvgH8b+A/pv33hcM/NBJV9YMkj8Q/DlrVz9rLMuA27blZfCf/x6r6VZJlSVJVX07yr12H\n6tD1VXVVs3LYTWZxAtbTVjt1ryRX0UxI+2UXmaQptFlVnbDa74s/dhVmMRbVGqXdaCZZbAw8MAlV\ndUS3kdSxH1fVKlvUJ3lmV2E6dFWSWwPfBo5I8kuacfez6kdJnkszufeeNBNZv9txpi68GHgoML/O\n/wrgZOBuSd5aVR/pKpg0RS5LsiO94aXPAKZyEqfDPzQSST4C7EgzTnJ+clbN2hJZWlWSH1TVA9d1\nbkOX5DY0s9eXAS8AtgSOqKrLOg3WkSSb0awU9FiaT7a+BPxjVf2+02ATluRLwAuqamV7vA3NuOrn\nAN+cxo+3pUlLcnfgEJplBq8Afg48r6rO7zTYAiyqNRJJzgR2Kv9DCUiyN/B44Fk0SyvO24Lm/8lu\nnQTrSJK3V9Wb1nVOsyXJj6tqp77jAD+qqp1maZdNaTFJ5ldEuRVNx8Q1NAshnFxVp3YWbAEO/9Co\nnEGzOPtUfiSjibsYOAl4Ms3H2fOuBl7bSaJu7QWsXkA/YYFzG7Qkn2ORMfVV9eQJxpkGc0k+T7Mu\nMcDT23ObA1d2F0uaKru2l2NoPtn6S+B04KVJPllV/9JluH72VGskknydZjvuE1h1x6NZ+yOpPkk2\noXnzPpPrESfZD3gpcC+g//u/DU0vyz6dBOtIO5kZ4Gk0b8Lnd9p8DrCyqmbqDVfbM/004OHtqSuA\nbarq5d2lkqZLkm8Cj6+q37bHtwb+h6az4uT+T3u6Zk+1RuXArgNoKu0F/CtwC5rJV7sAb52hN1uf\nAL4KvAN4Q9/5q2dxdYeq+gZAkndW1a59N30uyUkdxepMVVWSc4HdgWfSjBU9qttU0tTZmr7OOprt\n27epqmuTXLeWx3TColojMf/HUlrNgTSrwswBVNWpSe7WZaBJqqoraHofn5nkvsCftTd9C5i5orrP\n5knuXlXnArT/JzbvONPEJLkXTe/8c4DLaOYdpKoe1WkwaTp9FDg+yWfb4ycB/90Ok/pxd7HWZFGt\nkWjXWz2I5h1l2ktV1RadBlPXFlqPeObGnCV5OfBy4Oj21CeS/FtVvb/DWF16Lc3Y4XNpfldsD+zX\nbaSJOovmjdUTq+qnAElmauiLNKiq+sckXwT2aE+9tKrmP9l6XkexFuSYao1Ekp8CT6qqM7vOoumR\n5FCa4Q9voJmE9Spgk6p6aafBJizJ6cDDVhsT+N2q2rnbZN1JckvgPu3hWVU1VR/jjlOSpwL70BQJ\nxwJHAh+qqpn5FEfaEC3rOoA2GCstqLWAVwL3pRkP9zHgN8BrOk3UjQB/6Du+vj03yx5E83/j/sCz\nk7yg4zwTU1VHt5NU70Oz8ctrgK2T/HuSx3abTtL6sqdaI5Hk3TSz+Y9m1dU/Pt1ZKKljSTauqj8m\neT3N+Nn5SWh/AXysqmZyq3I3i1pTktvRTFZ8dlXt2XUeSTefRbVGIslhC5yuqnrRxMOoc0mOWez2\nWVn9o3/3yCS70Vs67VtVdWJ3ybrlZlGSNkROVNRIVNW+XWfQVHkocAHNkI/jmd2hDjd931V1As06\n7nKzKEkbIHuqNRJtT/Ua/5nsqZ5NSTYCHkMz5GFnmoX6P1ZVP+o02IQluRA4eG23V9Vab9uQuVmU\npA2RPdUalc/3Xd+UZszoxR1lUceq6gaaVQ2ObVd5eA7NEmpvqar3dZtuojYCbs3s9tSvzYFdB5Ck\nUbOnWmORZBnw7ap6WNdZ1I22mH4CTUG9A3AM8OGquqjLXJPUP6Zaq0qyPXDPqvpKks2Ajarq6q5z\nSdL6sqda43JPmo1gNIOSHAHcD/gC8JaqOqPjSF2xh3oBSV4C/A2wFc0qINsCHwBc9ULSkmVPtYaW\nZru8G4Df9p2+FHhjVR218KO0IUtyI3BNe9j/S2amdtpMslVVXd51jmmT5FSa7euPr6oHtOd+WFV/\n2m0ySVp/9lRraFVVSX5cVffrOoumQ1W5sRRgQb1W11XVH+a3r0+yMTO4fb2kDYt/+DQqJyd5cNch\nJC0J30jyJuBWSR4DfBL4XMeZJGkoDv/QSCQ5C7gHcD7Nx/7zH/Pv3GkwSVOnncj8YmB+S+4vVdWH\nOowkSUOzqNZItDP511BV5086i6TplOQpwF2q6t/a4xOAO9IM/Xh9VX2qy3ySNAyLaknSRCT5DrBP\nVV3QHp8KPJpmLe/DqsrVPyQtWU5UlCRNyi3mC+rWt9vJnJcn2byrUJI0Ck5UlCRNyu36D6rqFX2H\nd5xwFkkaKYtqSdKkHN9u/LKKJPsBJ3SQR5JGxjHVkqSJSLI1cDRwHfCD9vSDgFsCT62qlV1lk6Rh\nWVRLkiYqyaOB+7aHP6qqr3WZR5JGwaJakiRJGpJjqiVJkqQhWVRLkiRJQ7KoliRJkoZkUS1JkiQN\nyaJakiRJGtL/B9MOtGGIDKi3AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1439a5850>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "modelfit(gsearch3.best_estimator_, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([mean: 0.65159, std: 0.02653, params: {'max_features': 1},\n",
       "  mean: 0.67288, std: 0.02768, params: {'max_features': 2},\n",
       "  mean: 0.67171, std: 0.02604, params: {'max_features': 3},\n",
       "  mean: 0.67884, std: 0.02182, params: {'max_features': 4},\n",
       "  mean: 0.67550, std: 0.01269, params: {'max_features': 5},\n",
       "  mean: 0.68055, std: 0.02184, params: {'max_features': 6},\n",
       "  mean: 0.67915, std: 0.02438, params: {'max_features': 7},\n",
       "  mean: 0.67826, std: 0.02419, params: {'max_features': 8},\n",
       "  mean: 0.67518, std: 0.01990, params: {'max_features': 9}],\n",
       " {'max_features': 6},\n",
       " 0.680550543103162)"
      ]
     },
     "execution_count": 1119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test4 = {'max_features':range(1,10,1)}\n",
    "gsearch4 = GridSearchCV(estimator = GBC(learning_rate=0.1, n_estimators=20,max_depth=5, min_samples_split=50, min_samples_leaf=5, subsample=0.8, random_state=10),\n",
    "param_grid = param_test4, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch4.fit(X_train,y_train)\n",
    "gsearch4.grid_scores_, gsearch4.best_params_, gsearch4.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
