{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 668,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.ensemble import GradientBoostingClassifier as GBC\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import log_loss, auc, roc_curve, roc_auc_score\n",
    "from sklearn.neighbors import KNeighborsClassifier as knn\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#data = pd.read_csv('../ult_sign_scrape/race_master/master_database.csv')\n",
    "fe4 = pd.read_csv('../ult_sign_scrape/race_master/master_database_fe4.csv')\n",
    "athletes = pd.read_csv('../ult_sign_scrape/athlete_dataframe/concat')\n",
    "races = pd.read_csv('../ult_sign_scrape/race_master/master_list.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#clean = data.drop(['Unnamed: 0', 'Unnamed: 0.1'], axis=1)\n",
    "fe4_clean = fe4.drop(['Unnamed: 0', 'Unnamed: 0.1'], axis=1)\n",
    "fe4 = fe4_clean.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>participant_id</th>\n",
       "      <th>runner_rank</th>\n",
       "      <th>status</th>\n",
       "      <th>race_id</th>\n",
       "      <th>Season</th>\n",
       "      <th>Metro_area</th>\n",
       "      <th>WL_SO</th>\n",
       "      <th>Age_Rank</th>\n",
       "      <th>Gender_Rank</th>\n",
       "      <th>Total_races</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.270411</td>\n",
       "      <td>-0.216783</td>\n",
       "      <td>0.075115</td>\n",
       "      <td>-0.010206</td>\n",
       "      <td>0.047769</td>\n",
       "      <td>0.018868</td>\n",
       "      <td>-0.042234</td>\n",
       "      <td>-0.007417</td>\n",
       "      <td>0.000602</td>\n",
       "      <td>0.011360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>participant_id</th>\n",
       "      <td>-0.270411</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.194335</td>\n",
       "      <td>-0.001664</td>\n",
       "      <td>0.386143</td>\n",
       "      <td>-0.020922</td>\n",
       "      <td>0.029178</td>\n",
       "      <td>-0.089267</td>\n",
       "      <td>-0.005315</td>\n",
       "      <td>-0.005174</td>\n",
       "      <td>-0.015240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>runner_rank</th>\n",
       "      <td>-0.216783</td>\n",
       "      <td>-0.194335</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.190380</td>\n",
       "      <td>0.020117</td>\n",
       "      <td>-0.074137</td>\n",
       "      <td>-0.018915</td>\n",
       "      <td>0.112452</td>\n",
       "      <td>-0.003333</td>\n",
       "      <td>-0.008166</td>\n",
       "      <td>0.007546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>status</th>\n",
       "      <td>0.075115</td>\n",
       "      <td>-0.001664</td>\n",
       "      <td>-0.190380</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.032448</td>\n",
       "      <td>0.079697</td>\n",
       "      <td>-0.038195</td>\n",
       "      <td>-0.150450</td>\n",
       "      <td>0.007557</td>\n",
       "      <td>0.009809</td>\n",
       "      <td>-0.000989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race_id</th>\n",
       "      <td>-0.010206</td>\n",
       "      <td>0.386143</td>\n",
       "      <td>0.020117</td>\n",
       "      <td>0.032448</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.058049</td>\n",
       "      <td>0.130348</td>\n",
       "      <td>-0.140636</td>\n",
       "      <td>-0.015521</td>\n",
       "      <td>-0.024019</td>\n",
       "      <td>-0.029799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Season</th>\n",
       "      <td>0.047769</td>\n",
       "      <td>-0.020922</td>\n",
       "      <td>-0.074137</td>\n",
       "      <td>0.079697</td>\n",
       "      <td>-0.058049</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.229057</td>\n",
       "      <td>-0.488075</td>\n",
       "      <td>-0.004094</td>\n",
       "      <td>-0.006021</td>\n",
       "      <td>0.019240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Metro_area</th>\n",
       "      <td>0.018868</td>\n",
       "      <td>0.029178</td>\n",
       "      <td>-0.018915</td>\n",
       "      <td>-0.038195</td>\n",
       "      <td>0.130348</td>\n",
       "      <td>-0.229057</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.306849</td>\n",
       "      <td>-0.010899</td>\n",
       "      <td>-0.017804</td>\n",
       "      <td>-0.007776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WL_SO</th>\n",
       "      <td>-0.042234</td>\n",
       "      <td>-0.089267</td>\n",
       "      <td>0.112452</td>\n",
       "      <td>-0.150450</td>\n",
       "      <td>-0.140636</td>\n",
       "      <td>-0.488075</td>\n",
       "      <td>-0.306849</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.027897</td>\n",
       "      <td>0.026131</td>\n",
       "      <td>0.011520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age_Rank</th>\n",
       "      <td>-0.007417</td>\n",
       "      <td>-0.005315</td>\n",
       "      <td>-0.003333</td>\n",
       "      <td>0.007557</td>\n",
       "      <td>-0.015521</td>\n",
       "      <td>-0.004094</td>\n",
       "      <td>-0.010899</td>\n",
       "      <td>0.027897</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.766592</td>\n",
       "      <td>0.177129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gender_Rank</th>\n",
       "      <td>0.000602</td>\n",
       "      <td>-0.005174</td>\n",
       "      <td>-0.008166</td>\n",
       "      <td>0.009809</td>\n",
       "      <td>-0.024019</td>\n",
       "      <td>-0.006021</td>\n",
       "      <td>-0.017804</td>\n",
       "      <td>0.026131</td>\n",
       "      <td>0.766592</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.157633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total_races</th>\n",
       "      <td>0.011360</td>\n",
       "      <td>-0.015240</td>\n",
       "      <td>0.007546</td>\n",
       "      <td>-0.000989</td>\n",
       "      <td>-0.029799</td>\n",
       "      <td>0.019240</td>\n",
       "      <td>-0.007776</td>\n",
       "      <td>0.011520</td>\n",
       "      <td>0.177129</td>\n",
       "      <td>0.157633</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     age  participant_id  runner_rank    status   race_id  \\\n",
       "age             1.000000       -0.270411    -0.216783  0.075115 -0.010206   \n",
       "participant_id -0.270411        1.000000    -0.194335 -0.001664  0.386143   \n",
       "runner_rank    -0.216783       -0.194335     1.000000 -0.190380  0.020117   \n",
       "status          0.075115       -0.001664    -0.190380  1.000000  0.032448   \n",
       "race_id        -0.010206        0.386143     0.020117  0.032448  1.000000   \n",
       "Season          0.047769       -0.020922    -0.074137  0.079697 -0.058049   \n",
       "Metro_area      0.018868        0.029178    -0.018915 -0.038195  0.130348   \n",
       "WL_SO          -0.042234       -0.089267     0.112452 -0.150450 -0.140636   \n",
       "Age_Rank       -0.007417       -0.005315    -0.003333  0.007557 -0.015521   \n",
       "Gender_Rank     0.000602       -0.005174    -0.008166  0.009809 -0.024019   \n",
       "Total_races     0.011360       -0.015240     0.007546 -0.000989 -0.029799   \n",
       "\n",
       "                  Season  Metro_area     WL_SO  Age_Rank  Gender_Rank  \\\n",
       "age             0.047769    0.018868 -0.042234 -0.007417     0.000602   \n",
       "participant_id -0.020922    0.029178 -0.089267 -0.005315    -0.005174   \n",
       "runner_rank    -0.074137   -0.018915  0.112452 -0.003333    -0.008166   \n",
       "status          0.079697   -0.038195 -0.150450  0.007557     0.009809   \n",
       "race_id        -0.058049    0.130348 -0.140636 -0.015521    -0.024019   \n",
       "Season          1.000000   -0.229057 -0.488075 -0.004094    -0.006021   \n",
       "Metro_area     -0.229057    1.000000 -0.306849 -0.010899    -0.017804   \n",
       "WL_SO          -0.488075   -0.306849  1.000000  0.027897     0.026131   \n",
       "Age_Rank       -0.004094   -0.010899  0.027897  1.000000     0.766592   \n",
       "Gender_Rank    -0.006021   -0.017804  0.026131  0.766592     1.000000   \n",
       "Total_races     0.019240   -0.007776  0.011520  0.177129     0.157633   \n",
       "\n",
       "                Total_races  \n",
       "age                0.011360  \n",
       "participant_id    -0.015240  \n",
       "runner_rank        0.007546  \n",
       "status            -0.000989  \n",
       "race_id           -0.029799  \n",
       "Season             0.019240  \n",
       "Metro_area        -0.007776  \n",
       "WL_SO              0.011520  \n",
       "Age_Rank           0.177129  \n",
       "Gender_Rank        0.157633  \n",
       "Total_races        1.000000  "
      ]
     },
     "execution_count": 713,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fe4.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting observation - Very little spread between 25-75% in age of entrants (35-49). Max is 79 and min is ~12 (some cleaning of 0/1 ages may be necessary). 39-44 is the most common ages with nearly 400 in each category. Mid-life crisis???\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting observation - Appears that runner rank and age have the strongest relationships to the status column. Gender rank and age rank are similar in their relationship. Total races appears to have the weakest relationship for these features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gender_dummies_fe = pd.get_dummies(fe4.gender, prefix='gender')\n",
    "#state_dummies = pd.get_dummies(fe2_clean.state, prefix='Home_State')\n",
    "fe4 = fe4.join(gender_dummies_fe)\n",
    "#fe4_clean = fe4_clean.join(state_dummies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Coding:\n",
      "1    6291\n",
      "2    3930\n",
      "3     540\n",
      "Name: status, dtype: int64\n",
      "\n",
      "After Coding:\n",
      "0    10221\n",
      "1      540\n",
      "Name: status_coded, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>participant_id</th>\n",
       "      <th>runner_rank</th>\n",
       "      <th>race_id</th>\n",
       "      <th>race_name</th>\n",
       "      <th>Season</th>\n",
       "      <th>Metro_area</th>\n",
       "      <th>WL_SO</th>\n",
       "      <th>Age_Rank</th>\n",
       "      <th>Gender_Rank</th>\n",
       "      <th>Total_races</th>\n",
       "      <th>gender_F</th>\n",
       "      <th>gender_M</th>\n",
       "      <th>status_coded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26</td>\n",
       "      <td>M</td>\n",
       "      <td>7148</td>\n",
       "      <td>88.39</td>\n",
       "      <td>11470</td>\n",
       "      <td>Bear</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7174</td>\n",
       "      <td>0.6806</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33</td>\n",
       "      <td>M</td>\n",
       "      <td>221721</td>\n",
       "      <td>90.00</td>\n",
       "      <td>11470</td>\n",
       "      <td>Bear</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8132</td>\n",
       "      <td>0.6987</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>43</td>\n",
       "      <td>M</td>\n",
       "      <td>20020</td>\n",
       "      <td>83.63</td>\n",
       "      <td>11470</td>\n",
       "      <td>Bear</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8272</td>\n",
       "      <td>0.7145</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36</td>\n",
       "      <td>M</td>\n",
       "      <td>25441</td>\n",
       "      <td>73.22</td>\n",
       "      <td>11470</td>\n",
       "      <td>Bear</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8995</td>\n",
       "      <td>0.8957</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>M</td>\n",
       "      <td>22562</td>\n",
       "      <td>87.77</td>\n",
       "      <td>11470</td>\n",
       "      <td>Bear</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6807</td>\n",
       "      <td>0.6522</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age gender  participant_id  runner_rank  race_id race_name  Season  \\\n",
       "0   26      M            7148        88.39    11470      Bear       3   \n",
       "1   33      M          221721        90.00    11470      Bear       3   \n",
       "2   43      M           20020        83.63    11470      Bear       3   \n",
       "3   36      M           25441        73.22    11470      Bear       3   \n",
       "4   33      M           22562        87.77    11470      Bear       3   \n",
       "\n",
       "   Metro_area  WL_SO  Age_Rank  Gender_Rank  Total_races  gender_F  gender_M  \\\n",
       "0           0      1    0.7174       0.6806         23.0       0.0       1.0   \n",
       "1           0      1    0.8132       0.6987          9.0       0.0       1.0   \n",
       "2           0      1    0.8272       0.7145         17.0       0.0       1.0   \n",
       "3           0      1    0.8995       0.8957         18.0       0.0       1.0   \n",
       "4           0      1    0.6807       0.6522          8.0       0.0       1.0   \n",
       "\n",
       "   status_coded  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             0  \n",
       "4             0  "
      ]
     },
     "execution_count": 715,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def coding(col, codeDict):\n",
    "    colCoded = pd.Series(col, copy=True)\n",
    "    for key, value in codeDict.items():\n",
    "        colCoded.replace(key, value, inplace=True)\n",
    "    return colCoded\n",
    " \n",
    "\n",
    "print 'Before Coding:'\n",
    "print pd.value_counts(fe4[\"status\"])\n",
    "fe4[\"status_coded\"] = coding(fe4[\"status\"], {'1':0,'2':0, '3':1})\n",
    "print '\\nAfter Coding:'\n",
    "print pd.value_counts(fe4[\"status_coded\"])\n",
    "fe4 = fe4.drop(['status'], axis=1)\n",
    "fe4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>participant_id</th>\n",
       "      <th>runner_rank</th>\n",
       "      <th>race_id</th>\n",
       "      <th>Season</th>\n",
       "      <th>Metro_area</th>\n",
       "      <th>WL_SO</th>\n",
       "      <th>Age_Rank</th>\n",
       "      <th>Gender_Rank</th>\n",
       "      <th>Total_races</th>\n",
       "      <th>gender_F</th>\n",
       "      <th>gender_M</th>\n",
       "      <th>status_coded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10761.000000</td>\n",
       "      <td>1.076100e+04</td>\n",
       "      <td>10761.000000</td>\n",
       "      <td>10761.000000</td>\n",
       "      <td>10761.000000</td>\n",
       "      <td>10761.000000</td>\n",
       "      <td>10761.000000</td>\n",
       "      <td>10761.000000</td>\n",
       "      <td>10761.000000</td>\n",
       "      <td>10761.000000</td>\n",
       "      <td>10761.000000</td>\n",
       "      <td>10761.000000</td>\n",
       "      <td>10761.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>42.779481</td>\n",
       "      <td>2.714212e+05</td>\n",
       "      <td>69.950043</td>\n",
       "      <td>24829.516866</td>\n",
       "      <td>2.469008</td>\n",
       "      <td>0.705139</td>\n",
       "      <td>0.636558</td>\n",
       "      <td>0.730872</td>\n",
       "      <td>0.667381</td>\n",
       "      <td>11.729951</td>\n",
       "      <td>0.251835</td>\n",
       "      <td>0.748165</td>\n",
       "      <td>0.050181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.865196</td>\n",
       "      <td>2.933872e+05</td>\n",
       "      <td>12.997761</td>\n",
       "      <td>8206.243441</td>\n",
       "      <td>0.736585</td>\n",
       "      <td>0.456001</td>\n",
       "      <td>0.481013</td>\n",
       "      <td>0.204156</td>\n",
       "      <td>0.170511</td>\n",
       "      <td>19.889423</td>\n",
       "      <td>0.434087</td>\n",
       "      <td>0.434087</td>\n",
       "      <td>0.218329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.890000e+02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11470.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>2.183900e+04</td>\n",
       "      <td>63.060000</td>\n",
       "      <td>17746.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.674800</td>\n",
       "      <td>0.602100</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>42.000000</td>\n",
       "      <td>1.686890e+05</td>\n",
       "      <td>69.890000</td>\n",
       "      <td>24962.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.762400</td>\n",
       "      <td>0.679400</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>4.350870e+05</td>\n",
       "      <td>77.470000</td>\n",
       "      <td>33769.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.849200</td>\n",
       "      <td>0.763800</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>79.000000</td>\n",
       "      <td>1.180368e+06</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>35969.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>247.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age  participant_id   runner_rank       race_id        Season  \\\n",
       "count  10761.000000    1.076100e+04  10761.000000  10761.000000  10761.000000   \n",
       "mean      42.779481    2.714212e+05     69.950043  24829.516866      2.469008   \n",
       "std        9.865196    2.933872e+05     12.997761   8206.243441      0.736585   \n",
       "min        0.000000    4.890000e+02      0.000000  11470.000000      1.000000   \n",
       "25%       35.000000    2.183900e+04     63.060000  17746.000000      2.000000   \n",
       "50%       42.000000    1.686890e+05     69.890000  24962.000000      3.000000   \n",
       "75%       50.000000    4.350870e+05     77.470000  33769.000000      3.000000   \n",
       "max       79.000000    1.180368e+06    100.000000  35969.000000      4.000000   \n",
       "\n",
       "         Metro_area         WL_SO      Age_Rank   Gender_Rank   Total_races  \\\n",
       "count  10761.000000  10761.000000  10761.000000  10761.000000  10761.000000   \n",
       "mean       0.705139      0.636558      0.730872      0.667381     11.729951   \n",
       "std        0.456001      0.481013      0.204156      0.170511     19.889423   \n",
       "min        0.000000      0.000000      0.000000      0.000000      1.000000   \n",
       "25%        0.000000      0.000000      0.674800      0.602100      1.000000   \n",
       "50%        1.000000      1.000000      0.762400      0.679400      2.000000   \n",
       "75%        1.000000      1.000000      0.849200      0.763800     15.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000    247.000000   \n",
       "\n",
       "           gender_F      gender_M  status_coded  \n",
       "count  10761.000000  10761.000000  10761.000000  \n",
       "mean       0.251835      0.748165      0.050181  \n",
       "std        0.434087      0.434087      0.218329  \n",
       "min        0.000000      0.000000      0.000000  \n",
       "25%        0.000000      0.000000      0.000000  \n",
       "50%        0.000000      1.000000      0.000000  \n",
       "75%        1.000000      1.000000      0.000000  \n",
       "max        1.000000      1.000000      1.000000  "
      ]
     },
     "execution_count": 716,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fe4.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once adding gender dummies, it appears that gender in and of itself may not be a great predictor of race status. Appears to be ~75% male and 25% female particitation in these races."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = fe4.pop('status_coded')\n",
    "clean = fe4.drop(['gender', 'participant_id', 'race_name', 'race_id', 'Age_Rank', 'Gender_Rank', 'Total_races'], axis=1)\n",
    "X = clean\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>runner_rank</th>\n",
       "      <th>Season</th>\n",
       "      <th>Metro_area</th>\n",
       "      <th>WL_SO</th>\n",
       "      <th>gender_F</th>\n",
       "      <th>gender_M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6813</th>\n",
       "      <td>41</td>\n",
       "      <td>85.23</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9042</th>\n",
       "      <td>30</td>\n",
       "      <td>88.92</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>55</td>\n",
       "      <td>74.19</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8822</th>\n",
       "      <td>49</td>\n",
       "      <td>73.58</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2141</th>\n",
       "      <td>26</td>\n",
       "      <td>70.61</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7656</th>\n",
       "      <td>51</td>\n",
       "      <td>62.76</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3742</th>\n",
       "      <td>35</td>\n",
       "      <td>64.51</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6739</th>\n",
       "      <td>48</td>\n",
       "      <td>58.96</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1247</th>\n",
       "      <td>24</td>\n",
       "      <td>85.52</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2143</th>\n",
       "      <td>52</td>\n",
       "      <td>56.98</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963</th>\n",
       "      <td>33</td>\n",
       "      <td>58.78</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>47</td>\n",
       "      <td>81.89</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4090</th>\n",
       "      <td>42</td>\n",
       "      <td>67.43</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>60</td>\n",
       "      <td>76.95</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3620</th>\n",
       "      <td>32</td>\n",
       "      <td>84.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>59</td>\n",
       "      <td>68.31</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5213</th>\n",
       "      <td>46</td>\n",
       "      <td>66.53</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>811</th>\n",
       "      <td>29</td>\n",
       "      <td>84.10</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6737</th>\n",
       "      <td>46</td>\n",
       "      <td>67.09</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5048</th>\n",
       "      <td>54</td>\n",
       "      <td>68.81</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5490</th>\n",
       "      <td>22</td>\n",
       "      <td>59.30</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2404</th>\n",
       "      <td>39</td>\n",
       "      <td>68.29</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3163</th>\n",
       "      <td>29</td>\n",
       "      <td>59.32</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4029</th>\n",
       "      <td>42</td>\n",
       "      <td>82.11</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8135</th>\n",
       "      <td>45</td>\n",
       "      <td>92.88</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6841</th>\n",
       "      <td>38</td>\n",
       "      <td>70.99</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6713</th>\n",
       "      <td>66</td>\n",
       "      <td>74.39</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5589</th>\n",
       "      <td>45</td>\n",
       "      <td>74.50</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3426</th>\n",
       "      <td>46</td>\n",
       "      <td>47.69</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>39</td>\n",
       "      <td>72.98</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9770</th>\n",
       "      <td>46</td>\n",
       "      <td>55.22</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6010</th>\n",
       "      <td>53</td>\n",
       "      <td>74.90</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8386</th>\n",
       "      <td>31</td>\n",
       "      <td>73.05</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9804</th>\n",
       "      <td>46</td>\n",
       "      <td>60.92</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8138</th>\n",
       "      <td>27</td>\n",
       "      <td>89.39</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5930</th>\n",
       "      <td>59</td>\n",
       "      <td>59.14</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2389</th>\n",
       "      <td>37</td>\n",
       "      <td>59.37</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4369</th>\n",
       "      <td>26</td>\n",
       "      <td>65.21</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8078</th>\n",
       "      <td>43</td>\n",
       "      <td>67.62</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8938</th>\n",
       "      <td>45</td>\n",
       "      <td>75.52</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5879</th>\n",
       "      <td>34</td>\n",
       "      <td>84.60</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5709</th>\n",
       "      <td>47</td>\n",
       "      <td>64.42</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6808</th>\n",
       "      <td>39</td>\n",
       "      <td>74.27</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9508</th>\n",
       "      <td>50</td>\n",
       "      <td>69.39</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9923</th>\n",
       "      <td>31</td>\n",
       "      <td>87.60</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8812</th>\n",
       "      <td>41</td>\n",
       "      <td>76.07</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10564</th>\n",
       "      <td>63</td>\n",
       "      <td>67.80</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4502</th>\n",
       "      <td>47</td>\n",
       "      <td>66.88</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7826</th>\n",
       "      <td>27</td>\n",
       "      <td>74.29</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1568</th>\n",
       "      <td>44</td>\n",
       "      <td>68.59</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5654</th>\n",
       "      <td>47</td>\n",
       "      <td>64.39</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5824</th>\n",
       "      <td>36</td>\n",
       "      <td>87.10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2625</th>\n",
       "      <td>44</td>\n",
       "      <td>67.08</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4205</th>\n",
       "      <td>45</td>\n",
       "      <td>71.01</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>23</td>\n",
       "      <td>85.52</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850</th>\n",
       "      <td>37</td>\n",
       "      <td>75.41</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6881</th>\n",
       "      <td>59</td>\n",
       "      <td>65.19</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8916</th>\n",
       "      <td>55</td>\n",
       "      <td>61.12</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7610</th>\n",
       "      <td>42</td>\n",
       "      <td>61.38</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3822</th>\n",
       "      <td>55</td>\n",
       "      <td>58.70</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7532 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  runner_rank  Season  Metro_area  WL_SO  gender_F  gender_M\n",
       "6813    41        85.23       4           1      0       1.0       0.0\n",
       "9042    30        88.92       1           1      1       0.0       1.0\n",
       "663     55        74.19       3           0      1       1.0       0.0\n",
       "8822    49        73.58       2           1      1       1.0       0.0\n",
       "2141    26        70.61       2           0      1       0.0       1.0\n",
       "7656    51        62.76       2           1      1       0.0       1.0\n",
       "3742    35        64.51       3           1      0       1.0       0.0\n",
       "6739    48        58.96       2           1      1       1.0       0.0\n",
       "1247    24        85.52       4           1      0       0.0       1.0\n",
       "2143    52        56.98       2           0      1       0.0       1.0\n",
       "963     33        58.78       3           0      1       0.0       1.0\n",
       "629     47        81.89       3           0      1       0.0       1.0\n",
       "4090    42        67.43       3           1      0       0.0       1.0\n",
       "999     60        76.95       3           0      1       1.0       0.0\n",
       "3620    32        84.80       3           1      0       1.0       0.0\n",
       "870     59        68.31       3           0      1       0.0       1.0\n",
       "5213    46        66.53       3           1      0       0.0       1.0\n",
       "811     29        84.10       3           0      1       0.0       1.0\n",
       "6737    46        67.09       2           1      1       0.0       1.0\n",
       "5048    54        68.81       3           1      0       0.0       1.0\n",
       "5490    22        59.30       3           1      0       0.0       1.0\n",
       "2404    39        68.29       2           0      1       0.0       1.0\n",
       "3163    29        59.32       3           1      0       0.0       1.0\n",
       "4029    42        82.11       3           1      0       0.0       1.0\n",
       "8135    45        92.88       2           1      1       0.0       1.0\n",
       "6841    38        70.99       4           1      0       0.0       1.0\n",
       "6713    66        74.39       2           1      1       0.0       1.0\n",
       "5589    45        74.50       3           1      0       0.0       1.0\n",
       "3426    46        47.69       3           1      0       1.0       0.0\n",
       "933     39        72.98       3           0      1       1.0       0.0\n",
       "...    ...          ...     ...         ...    ...       ...       ...\n",
       "9770    46        55.22       3           0      1       0.0       1.0\n",
       "6010    53        74.90       2           1      1       0.0       1.0\n",
       "8386    31        73.05       2           1      1       1.0       0.0\n",
       "9804    46        60.92       3           0      1       0.0       1.0\n",
       "8138    27        89.39       2           1      1       0.0       1.0\n",
       "5930    59        59.14       2           1      1       0.0       1.0\n",
       "2389    37        59.37       2           0      1       0.0       1.0\n",
       "4369    26        65.21       3           1      0       0.0       1.0\n",
       "8078    43        67.62       2           1      1       1.0       0.0\n",
       "8938    45        75.52       1           1      1       0.0       1.0\n",
       "5879    34        84.60       2           1      1       1.0       0.0\n",
       "5709    47        64.42       2           1      1       0.0       1.0\n",
       "6808    39        74.27       4           1      0       0.0       1.0\n",
       "9508    50        69.39       1           1      1       0.0       1.0\n",
       "9923    31        87.60       3           0      1       1.0       0.0\n",
       "8812    41        76.07       2           1      1       0.0       1.0\n",
       "10564   63        67.80       3           0      1       1.0       0.0\n",
       "4502    47        66.88       3           1      0       1.0       0.0\n",
       "7826    27        74.29       2           1      1       0.0       1.0\n",
       "1568    44        68.59       1           1      0       1.0       0.0\n",
       "5654    47        64.39       3           1      0       0.0       1.0\n",
       "5824    36        87.10       2           1      1       0.0       1.0\n",
       "2625    44        67.08       1           1      1       0.0       1.0\n",
       "4205    45        71.01       3           1      0       1.0       0.0\n",
       "1499    23        85.52       1           1      0       0.0       1.0\n",
       "850     37        75.41       3           0      1       0.0       1.0\n",
       "6881    59        65.19       4           1      0       0.0       1.0\n",
       "8916    55        61.12       2           1      1       0.0       1.0\n",
       "7610    42        61.38       2           1      1       0.0       1.0\n",
       "3822    55        58.70       3           1      0       0.0       1.0\n",
       "\n",
       "[7532 rows x 7 columns]"
      ]
     },
     "execution_count": 719,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 720,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LR()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predicted = model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19158459921967103"
      ]
     },
     "execution_count": 722,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(y_test, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -5.49432081e-03,  -6.35661033e-04,  -1.64751578e-01,\n",
       "         -9.06675676e-01,  -9.22660826e-01,  -4.51577784e-01,\n",
       "         -3.17041564e-01]])"
      ]
     },
     "execution_count": 723,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 725,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33019931874703312"
      ]
     },
     "execution_count": 725,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = RFC(n_estimators=5000, criterion='entropy', random_state=1, n_jobs=2)\n",
    "model2.fit(X_train, y_train)\n",
    "predicted2 = model2.predict_proba(X_test)\n",
    "log_loss(y_test, predicted2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 727,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18681267212318881"
      ]
     },
     "execution_count": 727,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3 = GBC()\n",
    "model3.fit(X_train, y_train)\n",
    "predictions = model3.predict_proba(X_test)\n",
    "log_loss(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7532, 7532, 3229, 3229)"
      ]
     },
     "execution_count": 708,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(y_train), len(X_test), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.60275639459107211"
      ]
     },
     "execution_count": 724,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "roc_auc_score(y_test, predicted[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 726,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71763705604431416"
      ]
     },
     "execution_count": 726,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Random Forest\n",
    "roc_auc_score(y_test, predicted2[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.68519061583577712"
      ]
     },
     "execution_count": 728,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#GBC\n",
    "fpr, tpr, thresholds = roc_curve(y_test, predictions[:,1])\n",
    "auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19955071357135232"
      ]
     },
     "execution_count": 685,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neighbor = knn(n_neighbors=1000, p=2, metric='minkowski')\n",
    "neighbor.fit(X_train, y_train)\n",
    "knn_predict = neighbor.predict_proba(X_test)\n",
    "log_loss(y_test, knn_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-fold cross validation:\n",
      "ROC AUC: 0.52 (+/- 0.05) [Logistic Regression]\n",
      "ROC AUC: 0.52 (+/- 0.03) [Decision Tree]\n",
      "ROC AUC: 0.51 (+/- 0.02) [KNN]\n"
     ]
    }
   ],
   "source": [
    "clf1 = LR(C=0.001, random_state=0)\n",
    "clf2 = DecisionTreeClassifier(max_depth=1, criterion='entropy', random_state=0)\n",
    "clf3 = knn(n_neighbors=1, p=2)\n",
    "pipe1 = Pipeline([['sc', StandardScaler()], ['clf', clf1]])\n",
    "pipe3 = Pipeline([['sc', StandardScaler()], ['clf', clf3]])\n",
    "clf_labels = ['Logistic Regression', 'Decision Tree', 'KNN']\n",
    "print '10-fold cross validation:'\n",
    "for clf, label in zip([pipe1, clf2, pipe3], clf_labels):\n",
    "    scores = cross_val_score(estimator=clf, X=X_train, y=y_train, cv=10, scoring='roc_auc')\n",
    "    print 'ROC AUC: %0.2f (+/- %0.2f) [%s]' % (scores.mean(), scores.std(), label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x14eee34d0>"
      ]
     },
     "execution_count": 515,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAEACAYAAABWLgY0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMaaQFxGJsf8PEAd1w8Y+afUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11f4e5950>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lst = ['r', 'b']\n",
    "new = ['r' if each == 1 else 'b' for each in y_test]\n",
    "plt.scatter(X_test['age'], y_test, c=new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = clean[y == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
