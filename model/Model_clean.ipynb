{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.ensemble import GradientBoostingClassifier as GBC\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import log_loss, auc, roc_curve, roc_auc_score, accuracy_score\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##Load data for final model\n",
    "data = pd.read_csv('../ult_sign_scrape/race_master/master_database_fe4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##Clean data by dropping extraneous columns\n",
    "cleaned_data = data.drop(['Unnamed: 0', 'Unnamed: 0.1'], axis=1)\n",
    "##Second stage of cleaning by removing na values from dataframe\n",
    "cleaned_data = cleaned_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##Create gender dummy variables for model\n",
    "gender_dummies = pd.get_dummies(cleaned_data.gender, prefix='gender')\n",
    "cleaned_data = cleaned_data.join(gender_dummies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Coding:\n",
      "1    6291\n",
      "2    3930\n",
      "3     540\n",
      "Name: status, dtype: int64\n",
      "\n",
      "After Coding:\n",
      "1    10221\n",
      "0      540\n",
      "Name: status_coded, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "##Consolidate all starts (code DNF with finishers) for modeling\n",
    "def coding(col, codeDict):\n",
    "    colCoded = pd.Series(col, copy=True)\n",
    "    for key, value in codeDict.items():\n",
    "        colCoded.replace(key, value, inplace=True)\n",
    "    return colCoded\n",
    " \n",
    "print 'Before Coding:'\n",
    "print pd.value_counts(cleaned_data[\"status\"])\n",
    "cleaned_data[\"status_coded\"] = coding(cleaned_data[\"status\"], {'1':1,'2':1, '3':0})\n",
    "print '\\nAfter Coding:'\n",
    "print pd.value_counts(cleaned_data[\"status_coded\"])\n",
    "status_coded = cleaned_data.drop(['status'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Set response variable for coded dataframe\n",
    "y_DNS = status_coded.pop('status_coded')\n",
    "##Set response variable for uncoded dataframe\n",
    "y_DNF = cleaned_data.pop('status')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##Set predictors for coded dataframe\n",
    "codedX = status_coded.drop(['gender', 'participant_id', 'race_name', 'race_id', 'Age_Rank', \\\n",
    "                  'Gender_Rank', 'Total_races'\\\n",
    "                 , 'gender_M'], axis=1)\n",
    "##Set predictors for uncoded dataframe\n",
    "uncodedX = cleaned_data.drop(['gender', 'participant_id', 'race_name', 'race_id', 'Age_Rank', \\\n",
    "                  'Gender_Rank', 'Total_races'\\\n",
    "                 , 'gender_M'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Create test/train splits for both datasets\n",
    "##coded dataframe\n",
    "cX_train, cX_test, cy_train, cy_test = train_test_split(codedX, y_DNS, test_size=0.3)\n",
    "##uncoded dataframe\n",
    "uX_train, uX_test, uy_train, uy_test = train_test_split(uncodedX, y_DNF, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.191067928831\n",
      "0.617058880692\n"
     ]
    }
   ],
   "source": [
    "##coded dataframe\n",
    "cLR = LR(C=10)\n",
    "cLR.fit(cX_train, cy_train)\n",
    "cLRp = cLR.predict_proba(cX_test)\n",
    "print log_loss(cy_test, cLRp)\n",
    "print roc_auc_score(cy_test, cLRp[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.590786228697\n",
      "0.679467327346\n"
     ]
    }
   ],
   "source": [
    "##uncoded dataframe\n",
    "uLR = LR(C=10)\n",
    "uLR.fit(uX_train, uy_train)\n",
    "uLRp = uLR.predict_proba(uX_test)\n",
    "uLRa = uLR.predict(uX_test)\n",
    "print log_loss(uy_test, uLRp)\n",
    "print accuracy_score(uy_test, uLRa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.387330076575\n",
      "0.750460574797\n"
     ]
    }
   ],
   "source": [
    "##coded dataframe\n",
    "cRF = RFC(n_estimators=500, criterion='entropy', random_state=1, n_jobs=2)\n",
    "cRF.fit(cX_train, cy_train)\n",
    "cRFp = cRF.predict_proba(cX_test)\n",
    "print log_loss(cy_test, cRFp)\n",
    "print roc_auc_score(cy_test, cRFp[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.623020139247\n",
      "0.702694332611\n"
     ]
    }
   ],
   "source": [
    "##uncoded dataframe\n",
    "uRF = RFC(n_estimators=500, criterion='entropy', random_state=1, n_jobs=2)\n",
    "uRF.fit(uX_train, uy_train)\n",
    "uRFp = uRF.predict_proba(uX_test)\n",
    "uRFa = uRF.predict(uX_test)\n",
    "print log_loss(uy_test, uRFp)\n",
    "print accuracy_score(uy_test, uRFa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosted Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.183943583194\n",
      "0.715731210573\n"
     ]
    }
   ],
   "source": [
    "##coded dataframe\n",
    "cGBC = GBC(n_estimators=50, max_depth=4, learning_rate=0.1)\n",
    "cGBC.fit(cX_train, cy_train)\n",
    "cGBCp = cGBC.predict_proba(cX_test)\n",
    "print log_loss(cy_test, cGBCp)\n",
    "print roc_auc_score(cy_test, cGBCp[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.578134160046\n",
      "0.689687209662\n"
     ]
    }
   ],
   "source": [
    "##uncoded dataframe\n",
    "uGBC = GBC(n_estimators=50, max_depth=4, learning_rate=0.1)\n",
    "uGBC.fit(uX_train, uy_train)\n",
    "uGBCp = uGBC.predict_proba(uX_test)\n",
    "uGBCa = uGBC.predict(uX_test)\n",
    "print log_loss(uy_test, uGBCp)\n",
    "print accuracy_score(uy_test, uGBCa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
